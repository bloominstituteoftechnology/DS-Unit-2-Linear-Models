{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": " SHARED DS 15 - Unit 2 - Sprint 1 - Module 3",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgansen/DS-Unit-2-Linear-Models/blob/master/module3-ridge-regression/SHARED_DS_15_Unit_2_Sprint_1_Module_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bznUCYpqtGC5",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2TgEa4UtGC6",
        "colab_type": "text"
      },
      "source": [
        "# Ridge Regression\n",
        "- Do one-hot encoding of categorical features\n",
        "- Do univariate feature selection\n",
        "- Use scikit-learn to fit Ridge Regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-7OFPGJtGC7",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below).\n",
        "\n",
        "Libraries:\n",
        "- category_encoders\n",
        "- matplotlib\n",
        "- numpy\n",
        "- pandas\n",
        "- scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TNyLYkq_tGC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwiY2sPetGC_",
        "colab_type": "text"
      },
      "source": [
        "# Do one-hot encoding of categorical features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t4fmtE0tGC_",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mslWRfstGDA",
        "colab_type": "text"
      },
      "source": [
        "First, let's load the NYC apartment rental listing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XAluKfFItGDA",
        "colab_type": "code",
        "outputId": "5de5d449-0e58-47d7-ecd8-9e71c593b07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read New York City apartment rental listing data\n",
        "df = pd.read_csv(DATA_PATH+'apartments/renthop-nyc.csv')\n",
        "assert df.shape == (49352, 34)\n",
        "\n",
        "\n",
        "# Remove the most extreme 1% prices,\n",
        "# the most extreme .1% latitudes, &\n",
        "# the most extreme .1% longitudes\n",
        "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
        "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
        "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
        "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
        "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
        "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]\n",
        "\n",
        "# Visualize distribution of target variable after trimming outliers.\n",
        "# Use distribution plot from seaborn.\n",
        "\n",
        "sns.distplot(df['price'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06ae0Jrzt4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do train/test split\n",
        "# Use data from April & May 2016 to train\n",
        "# Use data from June 2016 to test\n",
        "df['created'] = pd.to_datetime(df['created'], infer_datetime_format=True)\n",
        "cutoff = pd.to_datetime('2016-06-01')\n",
        "train = df[df.created < cutoff]\n",
        "test = df[df.created >= cutoff]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG3gV4YwtGDD",
        "colab_type": "text"
      },
      "source": [
        "Some columns are numeric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oaKWvCVctGDD",
        "colab_type": "code",
        "outputId": "d6748c9a-dee1-4e17-a338-307db27cd23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "train.describe(include='number')\n",
        "# Cardinality = number of unique values in a categorical variable\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>price</th>\n",
              "      <th>elevator</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>hardwood_floors</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>doorman</th>\n",
              "      <th>dishwasher</th>\n",
              "      <th>no_fee</th>\n",
              "      <th>laundry_in_building</th>\n",
              "      <th>fitness_center</th>\n",
              "      <th>pre-war</th>\n",
              "      <th>laundry_in_unit</th>\n",
              "      <th>roof_deck</th>\n",
              "      <th>outdoor_space</th>\n",
              "      <th>dining_room</th>\n",
              "      <th>high_speed_internet</th>\n",
              "      <th>balcony</th>\n",
              "      <th>swimming_pool</th>\n",
              "      <th>new_construction</th>\n",
              "      <th>terrace</th>\n",
              "      <th>exclusive</th>\n",
              "      <th>loft</th>\n",
              "      <th>garden_patio</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>common_outdoor_space</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.203728</td>\n",
              "      <td>1.528357</td>\n",
              "      <td>40.750743</td>\n",
              "      <td>-73.972867</td>\n",
              "      <td>3575.604007</td>\n",
              "      <td>0.530430</td>\n",
              "      <td>0.477139</td>\n",
              "      <td>0.480907</td>\n",
              "      <td>0.445861</td>\n",
              "      <td>0.430725</td>\n",
              "      <td>0.418666</td>\n",
              "      <td>0.369834</td>\n",
              "      <td>0.057311</td>\n",
              "      <td>0.267586</td>\n",
              "      <td>0.185938</td>\n",
              "      <td>0.175700</td>\n",
              "      <td>0.133777</td>\n",
              "      <td>0.143983</td>\n",
              "      <td>0.104290</td>\n",
              "      <td>0.088620</td>\n",
              "      <td>0.060734</td>\n",
              "      <td>0.055929</td>\n",
              "      <td>0.051470</td>\n",
              "      <td>0.047733</td>\n",
              "      <td>0.042269</td>\n",
              "      <td>0.044216</td>\n",
              "      <td>0.039222</td>\n",
              "      <td>0.028388</td>\n",
              "      <td>0.029048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.472447</td>\n",
              "      <td>1.105061</td>\n",
              "      <td>0.038658</td>\n",
              "      <td>0.028910</td>\n",
              "      <td>1762.136694</td>\n",
              "      <td>0.499081</td>\n",
              "      <td>0.499485</td>\n",
              "      <td>0.499643</td>\n",
              "      <td>0.497068</td>\n",
              "      <td>0.495185</td>\n",
              "      <td>0.493348</td>\n",
              "      <td>0.482767</td>\n",
              "      <td>0.232439</td>\n",
              "      <td>0.442707</td>\n",
              "      <td>0.389062</td>\n",
              "      <td>0.380571</td>\n",
              "      <td>0.340418</td>\n",
              "      <td>0.351078</td>\n",
              "      <td>0.305641</td>\n",
              "      <td>0.284198</td>\n",
              "      <td>0.238845</td>\n",
              "      <td>0.229788</td>\n",
              "      <td>0.220957</td>\n",
              "      <td>0.213203</td>\n",
              "      <td>0.201204</td>\n",
              "      <td>0.205577</td>\n",
              "      <td>0.194127</td>\n",
              "      <td>0.166082</td>\n",
              "      <td>0.167943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.575700</td>\n",
              "      <td>-74.087300</td>\n",
              "      <td>1375.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.728500</td>\n",
              "      <td>-73.991800</td>\n",
              "      <td>2500.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.751700</td>\n",
              "      <td>-73.978100</td>\n",
              "      <td>3150.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>40.773600</td>\n",
              "      <td>-73.955000</td>\n",
              "      <td>4095.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>40.910200</td>\n",
              "      <td>-73.700100</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          bathrooms      bedrooms  ...  wheelchair_access  common_outdoor_space\n",
              "count  31844.000000  31844.000000  ...       31844.000000          31844.000000\n",
              "mean       1.203728      1.528357  ...           0.028388              0.029048\n",
              "std        0.472447      1.105061  ...           0.166082              0.167943\n",
              "min        0.000000      0.000000  ...           0.000000              0.000000\n",
              "25%        1.000000      1.000000  ...           0.000000              0.000000\n",
              "50%        1.000000      1.000000  ...           0.000000              0.000000\n",
              "75%        1.000000      2.000000  ...           0.000000              0.000000\n",
              "max       10.000000      7.000000  ...           1.000000              1.000000\n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFKmvicJtGDG",
        "colab_type": "text"
      },
      "source": [
        "Some columns are _not_ numeric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6iV9Xsu0tGDG",
        "colab_type": "code",
        "outputId": "ba7142d1-7372-4c57-f8f8-8f77e9299eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "train.describe(exclude='number')\n",
        "# Cardinality = number of unique values in a categorical variable\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created</th>\n",
              "      <th>description</th>\n",
              "      <th>display_address</th>\n",
              "      <th>street_address</th>\n",
              "      <th>interest_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31844</td>\n",
              "      <td>30875</td>\n",
              "      <td>31775</td>\n",
              "      <td>31838</td>\n",
              "      <td>31844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>31436</td>\n",
              "      <td>25735</td>\n",
              "      <td>6468</td>\n",
              "      <td>11280</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>2016-05-14 01:11:03</td>\n",
              "      <td></td>\n",
              "      <td>Broadway</td>\n",
              "      <td>505 West 37th Street</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>906</td>\n",
              "      <td>273</td>\n",
              "      <td>120</td>\n",
              "      <td>22053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first</th>\n",
              "      <td>2016-04-01 22:12:41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>last</th>\n",
              "      <td>2016-05-31 23:10:48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    created description  ...        street_address interest_level\n",
              "count                 31844       30875  ...                 31838          31844\n",
              "unique                31436       25735  ...                 11280              3\n",
              "top     2016-05-14 01:11:03              ...  505 West 37th Street            low\n",
              "freq                      3         906  ...                   120          22053\n",
              "first   2016-04-01 22:12:41         NaN  ...                   NaN            NaN\n",
              "last    2016-05-31 23:10:48         NaN  ...                   NaN            NaN\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH82mvA70jqJ",
        "colab_type": "code",
        "outputId": "e114f50e-16a3-4f58-b59b-495680b52789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "train.describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>created</th>\n",
              "      <th>description</th>\n",
              "      <th>display_address</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>price</th>\n",
              "      <th>street_address</th>\n",
              "      <th>interest_level</th>\n",
              "      <th>elevator</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>hardwood_floors</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>doorman</th>\n",
              "      <th>dishwasher</th>\n",
              "      <th>no_fee</th>\n",
              "      <th>laundry_in_building</th>\n",
              "      <th>fitness_center</th>\n",
              "      <th>pre-war</th>\n",
              "      <th>laundry_in_unit</th>\n",
              "      <th>roof_deck</th>\n",
              "      <th>outdoor_space</th>\n",
              "      <th>dining_room</th>\n",
              "      <th>high_speed_internet</th>\n",
              "      <th>balcony</th>\n",
              "      <th>swimming_pool</th>\n",
              "      <th>new_construction</th>\n",
              "      <th>terrace</th>\n",
              "      <th>exclusive</th>\n",
              "      <th>loft</th>\n",
              "      <th>garden_patio</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>common_outdoor_space</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844</td>\n",
              "      <td>30875</td>\n",
              "      <td>31775</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31838</td>\n",
              "      <td>31844</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "      <td>31844.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31436</td>\n",
              "      <td>25735</td>\n",
              "      <td>6468</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11280</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-05-14 01:11:03</td>\n",
              "      <td></td>\n",
              "      <td>Broadway</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>505 West 37th Street</td>\n",
              "      <td>low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>906</td>\n",
              "      <td>273</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>120</td>\n",
              "      <td>22053</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-04-01 22:12:41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>last</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-05-31 23:10:48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.203728</td>\n",
              "      <td>1.528357</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.750743</td>\n",
              "      <td>-73.972867</td>\n",
              "      <td>3575.604007</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.530430</td>\n",
              "      <td>0.477139</td>\n",
              "      <td>0.480907</td>\n",
              "      <td>0.445861</td>\n",
              "      <td>0.430725</td>\n",
              "      <td>0.418666</td>\n",
              "      <td>0.369834</td>\n",
              "      <td>0.057311</td>\n",
              "      <td>0.267586</td>\n",
              "      <td>0.185938</td>\n",
              "      <td>0.175700</td>\n",
              "      <td>0.133777</td>\n",
              "      <td>0.143983</td>\n",
              "      <td>0.104290</td>\n",
              "      <td>0.088620</td>\n",
              "      <td>0.060734</td>\n",
              "      <td>0.055929</td>\n",
              "      <td>0.051470</td>\n",
              "      <td>0.047733</td>\n",
              "      <td>0.042269</td>\n",
              "      <td>0.044216</td>\n",
              "      <td>0.039222</td>\n",
              "      <td>0.028388</td>\n",
              "      <td>0.029048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.472447</td>\n",
              "      <td>1.105061</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.038658</td>\n",
              "      <td>0.028910</td>\n",
              "      <td>1762.136694</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.499081</td>\n",
              "      <td>0.499485</td>\n",
              "      <td>0.499643</td>\n",
              "      <td>0.497068</td>\n",
              "      <td>0.495185</td>\n",
              "      <td>0.493348</td>\n",
              "      <td>0.482767</td>\n",
              "      <td>0.232439</td>\n",
              "      <td>0.442707</td>\n",
              "      <td>0.389062</td>\n",
              "      <td>0.380571</td>\n",
              "      <td>0.340418</td>\n",
              "      <td>0.351078</td>\n",
              "      <td>0.305641</td>\n",
              "      <td>0.284198</td>\n",
              "      <td>0.238845</td>\n",
              "      <td>0.229788</td>\n",
              "      <td>0.220957</td>\n",
              "      <td>0.213203</td>\n",
              "      <td>0.201204</td>\n",
              "      <td>0.205577</td>\n",
              "      <td>0.194127</td>\n",
              "      <td>0.166082</td>\n",
              "      <td>0.167943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.575700</td>\n",
              "      <td>-74.087300</td>\n",
              "      <td>1375.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.728500</td>\n",
              "      <td>-73.991800</td>\n",
              "      <td>2500.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.751700</td>\n",
              "      <td>-73.978100</td>\n",
              "      <td>3150.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.773600</td>\n",
              "      <td>-73.955000</td>\n",
              "      <td>4095.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.910200</td>\n",
              "      <td>-73.700100</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           bathrooms      bedrooms  ... wheelchair_access common_outdoor_space\n",
              "count   31844.000000  31844.000000  ...      31844.000000         31844.000000\n",
              "unique           NaN           NaN  ...               NaN                  NaN\n",
              "top              NaN           NaN  ...               NaN                  NaN\n",
              "freq             NaN           NaN  ...               NaN                  NaN\n",
              "first            NaN           NaN  ...               NaN                  NaN\n",
              "last             NaN           NaN  ...               NaN                  NaN\n",
              "mean        1.203728      1.528357  ...          0.028388             0.029048\n",
              "std         0.472447      1.105061  ...          0.166082             0.167943\n",
              "min         0.000000      0.000000  ...          0.000000             0.000000\n",
              "25%         1.000000      1.000000  ...          0.000000             0.000000\n",
              "50%         1.000000      1.000000  ...          0.000000             0.000000\n",
              "75%         1.000000      2.000000  ...          0.000000             0.000000\n",
              "max        10.000000      7.000000  ...          1.000000             1.000000\n",
              "\n",
              "[13 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjnSK6kutGDI",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the relationship between `interest_level` and `price`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IlvhaFnOtGDJ",
        "colab_type": "code",
        "outputId": "5a737538-0da1-460b-edc2-9f463a15949e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# TODO\n",
        "\n",
        "train['interest_level'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "low       22053\n",
              "medium     7381\n",
              "high       2410\n",
              "Name: interest_level, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY2T94B51FPO",
        "colab_type": "code",
        "outputId": "b1ed7144-a045-4e34-99b1-27195a1efc8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "train['interest_level'].value_counts(normalize=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "low       0.692532\n",
              "medium    0.231786\n",
              "high      0.075681\n",
              "Name: interest_level, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nzKFpWQ1QXR",
        "colab_type": "code",
        "outputId": "d86b33b3-9cfa-4043-f5ec-ecbac177f3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "sns.countplot(train['interest_level'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f20749b9470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An3a8OZ5tGDL",
        "colab_type": "text"
      },
      "source": [
        "Interest Level seems like a useful, predictive feature. But it's a string  and our scikit-learn models expect all inputs to be numbers. \n",
        "\n",
        "So, we can \"one-hot encode\" the feature.\n",
        "\n",
        "To go from this:\n",
        "\n",
        "| interest_level |\n",
        "|----------------|\n",
        "| high           |\n",
        "| medium         |\n",
        "| low            |\n",
        "\n",
        "\n",
        "To this:\n",
        "\n",
        "| interest_level_high | interest_level_medium | interest_level_low |\n",
        "|---------------------|-----------------------|--------------------|\n",
        "| 1                   | 0                     | 0                  |\n",
        "| 0                   | 1                     | 0                  |\n",
        "| 0                   | 0                     | 1                  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qlrcG5vtGDM",
        "colab_type": "text"
      },
      "source": [
        "\"One-hot encoding\" adds a dimension for each unique value of each categorical feature. So, it may not be a good choice for \"high cardinality\" categoricals that have dozens, hundreds, or thousands of unique values. \n",
        "\n",
        "[Cardinality](https://simple.wikipedia.org/wiki/Cardinality) means the number of unique values that a feature has:\n",
        "> In mathematics, the cardinality of a set means the number of its elements. For example, the set A = {2, 4, 6} contains 3 elements, and therefore A has a cardinality of 3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcVZcVwatGDM",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWOZxE8btGDN",
        "colab_type": "text"
      },
      "source": [
        "The other non-numeric columns have high cardinality. So let's exclude them from our features for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mR5VPi_TtGDN",
        "colab_type": "code",
        "outputId": "0e8a68c5-c0bd-495b-cb58-5c9165209615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "target = 'price'\n",
        "high_cardinality = ['display_address', 'street_address', 'description', 'created']\n",
        "features = train.columns.drop([target] + high_cardinality)\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bathrooms', 'bedrooms', 'latitude', 'longitude', 'interest_level',\n",
              "       'elevator', 'cats_allowed', 'hardwood_floors', 'dogs_allowed',\n",
              "       'doorman', 'dishwasher', 'no_fee', 'laundry_in_building',\n",
              "       'fitness_center', 'pre-war', 'laundry_in_unit', 'roof_deck',\n",
              "       'outdoor_space', 'dining_room', 'high_speed_internet', 'balcony',\n",
              "       'swimming_pool', 'new_construction', 'terrace', 'exclusive', 'loft',\n",
              "       'garden_patio', 'wheelchair_access', 'common_outdoor_space'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv1obisK2JOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_16gnxyHtGDP",
        "colab_type": "text"
      },
      "source": [
        "Here's what `X_train` looks like **before** encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1RwH3zkFtGDQ",
        "colab_type": "code",
        "outputId": "db4032de-a4e6-41ef-dd29-035069177c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_test.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((31844, 29), (16973, 29))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL9lD-p13IoF",
        "colab_type": "code",
        "outputId": "43a5e36e-873d-4c35-d7eb-d2a935d0445e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>interest_level</th>\n",
              "      <th>elevator</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>hardwood_floors</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>doorman</th>\n",
              "      <th>dishwasher</th>\n",
              "      <th>no_fee</th>\n",
              "      <th>laundry_in_building</th>\n",
              "      <th>fitness_center</th>\n",
              "      <th>pre-war</th>\n",
              "      <th>laundry_in_unit</th>\n",
              "      <th>roof_deck</th>\n",
              "      <th>outdoor_space</th>\n",
              "      <th>dining_room</th>\n",
              "      <th>high_speed_internet</th>\n",
              "      <th>balcony</th>\n",
              "      <th>swimming_pool</th>\n",
              "      <th>new_construction</th>\n",
              "      <th>terrace</th>\n",
              "      <th>exclusive</th>\n",
              "      <th>loft</th>\n",
              "      <th>garden_patio</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>common_outdoor_space</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7388</td>\n",
              "      <td>-74.0018</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7539</td>\n",
              "      <td>-73.9677</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.8241</td>\n",
              "      <td>-73.9493</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.7429</td>\n",
              "      <td>-74.0028</td>\n",
              "      <td>medium</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>40.8012</td>\n",
              "      <td>-73.9660</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49346</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7296</td>\n",
              "      <td>-73.9869</td>\n",
              "      <td>medium</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49348</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7102</td>\n",
              "      <td>-74.0163</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49349</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7601</td>\n",
              "      <td>-73.9900</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49350</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>40.7066</td>\n",
              "      <td>-74.0101</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49351</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>40.8699</td>\n",
              "      <td>-73.9172</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31844 rows  29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       bathrooms  bedrooms  ...  wheelchair_access  common_outdoor_space\n",
              "2            1.0         1  ...                  0                     0\n",
              "3            1.0         1  ...                  0                     0\n",
              "4            1.0         4  ...                  0                     0\n",
              "5            2.0         4  ...                  0                     0\n",
              "6            1.0         2  ...                  0                     0\n",
              "...          ...       ...  ...                ...                   ...\n",
              "49346        1.0         1  ...                  0                     0\n",
              "49348        1.0         1  ...                  0                     1\n",
              "49349        1.0         1  ...                  0                     0\n",
              "49350        1.0         0  ...                  0                     0\n",
              "49351        1.0         2  ...                  0                     0\n",
              "\n",
              "[31844 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n_LD4oNtGDS",
        "colab_type": "text"
      },
      "source": [
        "Use [OneHotEncoder](https://contrib.scikit-learn.org/categorical-encoding/onehot.html) from the [category_encoders](https://github.com/scikit-learn-contrib/categorical-encoding) library to encode any non-numeric features. (In this case, it's just `interest_level`.)\n",
        "\n",
        "- Use the **`fit_transform`** method on the **train** set\n",
        "- Use the **`transform`** method on **validation / test** sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cUyr54tItGDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Estimator = anything with a .fit() method: includes models, tranformers\n",
        "# Predictor = anything with a .predict() method: includes models\n",
        "# Transformer = anything with a .transform() method: includes transformers\n",
        "\n",
        "import category_encoders as ce\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "X_test = encoder.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTV9fR4dtGDU",
        "colab_type": "text"
      },
      "source": [
        "Here's what it looks like **after:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i_3LU2C0tGDV",
        "colab_type": "code",
        "outputId": "09aca51a-b1bb-44f5-f339-c05d7bd8ba5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "# TODO\n",
        "\n",
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>interest_level_high</th>\n",
              "      <th>interest_level_low</th>\n",
              "      <th>interest_level_medium</th>\n",
              "      <th>elevator</th>\n",
              "      <th>cats_allowed</th>\n",
              "      <th>hardwood_floors</th>\n",
              "      <th>dogs_allowed</th>\n",
              "      <th>doorman</th>\n",
              "      <th>dishwasher</th>\n",
              "      <th>no_fee</th>\n",
              "      <th>laundry_in_building</th>\n",
              "      <th>fitness_center</th>\n",
              "      <th>pre-war</th>\n",
              "      <th>laundry_in_unit</th>\n",
              "      <th>roof_deck</th>\n",
              "      <th>outdoor_space</th>\n",
              "      <th>dining_room</th>\n",
              "      <th>high_speed_internet</th>\n",
              "      <th>balcony</th>\n",
              "      <th>swimming_pool</th>\n",
              "      <th>new_construction</th>\n",
              "      <th>terrace</th>\n",
              "      <th>exclusive</th>\n",
              "      <th>loft</th>\n",
              "      <th>garden_patio</th>\n",
              "      <th>wheelchair_access</th>\n",
              "      <th>common_outdoor_space</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7388</td>\n",
              "      <td>-74.0018</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7539</td>\n",
              "      <td>-73.9677</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.8241</td>\n",
              "      <td>-73.9493</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>40.7429</td>\n",
              "      <td>-74.0028</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>40.8012</td>\n",
              "      <td>-73.9660</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49346</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7296</td>\n",
              "      <td>-73.9869</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49348</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7102</td>\n",
              "      <td>-74.0163</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49349</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40.7601</td>\n",
              "      <td>-73.9900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49350</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>40.7066</td>\n",
              "      <td>-74.0101</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49351</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>40.8699</td>\n",
              "      <td>-73.9172</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31844 rows  31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       bathrooms  bedrooms  ...  wheelchair_access  common_outdoor_space\n",
              "2            1.0         1  ...                  0                     0\n",
              "3            1.0         1  ...                  0                     0\n",
              "4            1.0         4  ...                  0                     0\n",
              "5            2.0         4  ...                  0                     0\n",
              "6            1.0         2  ...                  0                     0\n",
              "...          ...       ...  ...                ...                   ...\n",
              "49346        1.0         1  ...                  0                     0\n",
              "49348        1.0         1  ...                  0                     1\n",
              "49349        1.0         1  ...                  0                     0\n",
              "49350        1.0         0  ...                  0                     0\n",
              "49351        1.0         2  ...                  0                     0\n",
              "\n",
              "[31844 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CaLXiuS3s-V",
        "colab_type": "code",
        "outputId": "533523ed-f22e-4da9-caee-c433b427fce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31844, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCRrSOAgtGDX",
        "colab_type": "text"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD4ZJWEntGDY",
        "colab_type": "text"
      },
      "source": [
        "In your assignment, you will do one-hot encoding of categorical features with feasible cardinality, using the category_encoders library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ipVNmHtGDY",
        "colab_type": "text"
      },
      "source": [
        "# Do univariate feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Laiqe_8GtGDY",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVSLxWJ2tGDZ",
        "colab_type": "text"
      },
      "source": [
        "The previous assignment quoted Wikipedia on [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering):\n",
        "\n",
        "> \"Some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.\" Pedro Domingos, [\"A Few Useful Things to Know about Machine Learning\"](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
        "\n",
        "> \"Coming up with features is difficult, time-consuming, requires expert knowledge. 'Applied machine learning' is basically feature engineering.\" Andrew Ng, [Machine Learning and AI via Brain simulations](https://forum.stanford.edu/events/2011/2011slides/plenary/2011plenaryNg.pdf) \n",
        "\n",
        "> Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. \n",
        "\n",
        "Pedro Domingos says, \"the most important factor is the **features used**.\"\n",
        "\n",
        "This includes not just **Feature Engineering** (making new features, representing features in new ways) but also **Feature Selection** (choosing which features to include and which to exclude).\n",
        "\n",
        "There are _many_ specific tools and techniques for feature selection.\n",
        "\n",
        "- Today we'll try [scikit-learn's `SelectKBest` transformer](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection), for \"univariate, forward selection.\"\n",
        "- Later we'll try another technique, [\"permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "- If you want to explore even more options, here are some good resources!\n",
        "  - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "  - [mlxtend](http://rasbt.github.io/mlxtend/) library\n",
        "  - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n",
        "  - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n",
        "\n",
        "\n",
        "My general recommendation is:\n",
        "\n",
        "> Predictive accuracy on test sets is the criterion for how good the model is.  Leo Breiman, [\"Statistical Modeling: The Two Cultures\"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IPa-bR5tGDZ",
        "colab_type": "text"
      },
      "source": [
        "First, let's engineer a few more features to select from. This is a partial example solution from the previous assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-DqL_m2xtGDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def engineer_features(X):\n",
        "    \n",
        "    # Avoid SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # How many total perks does each apartment have?\n",
        "    perk_cols = ['elevator', 'cats_allowed', 'hardwood_floors', 'dogs_allowed',\n",
        "                 'doorman', 'dishwasher', 'no_fee', 'laundry_in_building',\n",
        "                 'fitness_center', 'pre-war', 'laundry_in_unit', 'roof_deck',\n",
        "                 'outdoor_space', 'dining_room', 'high_speed_internet', 'balcony',\n",
        "                 'swimming_pool', 'new_construction', 'exclusive', 'terrace', \n",
        "                 'loft', 'garden_patio', 'common_outdoor_space', \n",
        "                 'wheelchair_access']\n",
        "    X['perk_count'] = X[perk_cols].sum(axis=1)\n",
        "\n",
        "    # Are cats or dogs allowed?\n",
        "    X['cats_or_dogs'] = (X['cats_allowed']==1) | (X['dogs_allowed']==1)\n",
        "\n",
        "    # Are cats and dogs allowed?\n",
        "    X['cats_and_dogs'] = (X['cats_allowed']==1) & (X['dogs_allowed']==1)\n",
        "\n",
        "    # Total number of rooms (beds + baths)\n",
        "    X['rooms'] = X['bedrooms'] + X['bathrooms']\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train = engineer_features(X_train)\n",
        "X_test = engineer_features(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7NcIGXItGDc",
        "colab_type": "text"
      },
      "source": [
        "### Could we try every possible feature combination?\n",
        "\n",
        "The number of [combinations](https://en.wikipedia.org/wiki/Combination) is shocking!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QNMt2axHtGDc",
        "colab_type": "code",
        "outputId": "c811eb1a-5fc0-4b5d-c62d-6b71d3043f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# How many features do we have currently?\n",
        "features = X_train.columns\n",
        "n = len(features)\n",
        "n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RsJwM6AptGDe",
        "colab_type": "code",
        "outputId": "b1713c34-4dbe-4b4f-d3cc-1ab7f88e19ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# How many ways to choose 1 to n features?\n",
        "from math import factorial\n",
        "\n",
        "def n_choose_k(n, k):\n",
        "    return factorial(n)/(factorial(k)*factorial(n-k))\n",
        "\n",
        "combinations = sum(n_choose_k(n,k) for k in range(1,n+1))\n",
        "print(f'{combinations:,.0f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34,359,738,367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwDMoWnMtGDg",
        "colab_type": "text"
      },
      "source": [
        "We can't try every possible combination, but we can try some. For example, we can use univariate statistical tests to measure the correlation between each feature and the target, and select the k best features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFTHnYT7tGDg",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpTxAm-BtGDh",
        "colab_type": "text"
      },
      "source": [
        "Refer to the [Scikit-Learn User Guide on Univariate Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BPeRr7dOtGDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Select the 15 features that best correlate with the target\n",
        "# (15 is an arbitrary starting point here)\n",
        "\n",
        "# SelectKBest has a similar API to what we've seen before.\n",
        "# IMPORTANT!\n",
        "# .fit_transform on the train set\n",
        "# .transform on test set\n",
        "\n",
        "# Import our class\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "# Instantiate our selector object\n",
        "selector = SelectKBest(k=15)\n",
        "\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFISPAzp8R8c",
        "colab_type": "code",
        "outputId": "e8cfe7f6-7dc8-4e21-a8cb-25b04714c977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_selected.shape, X_test_selected.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((31844, 15), (16973, 15))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KldVkMS9tGDj",
        "colab_type": "code",
        "outputId": "cde8dfbc-ff6a-4d32-be59-50f5c770d29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "# TODO: Which features were selected?\n",
        "\n",
        "selected_mask = selector.get_support()\n",
        "all_names = X_train.columns\n",
        "selected_names = all_names[selected_mask]\n",
        "unselected_names = all_names[~selected_mask]\n",
        "\n",
        "print ('Features selected:')\n",
        "for name in selected_names:\n",
        "  print (name)\n",
        "\n",
        "print ('Features excluded:')\n",
        "for name in unselected_names:\n",
        "  print (name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features selected:\n",
            "bathrooms\n",
            "bedrooms\n",
            "longitude\n",
            "elevator\n",
            "doorman\n",
            "dishwasher\n",
            "fitness_center\n",
            "laundry_in_unit\n",
            "roof_deck\n",
            "dining_room\n",
            "high_speed_internet\n",
            "new_construction\n",
            "wheelchair_access\n",
            "perk_count\n",
            "rooms\n",
            "Features excluded:\n",
            "latitude\n",
            "interest_level_high\n",
            "interest_level_low\n",
            "interest_level_medium\n",
            "cats_allowed\n",
            "hardwood_floors\n",
            "dogs_allowed\n",
            "no_fee\n",
            "laundry_in_building\n",
            "pre-war\n",
            "outdoor_space\n",
            "balcony\n",
            "swimming_pool\n",
            "terrace\n",
            "exclusive\n",
            "loft\n",
            "garden_patio\n",
            "common_outdoor_space\n",
            "cats_or_dogs\n",
            "cats_and_dogs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9v53TLD9gBX",
        "colab_type": "code",
        "outputId": "9c69f3a9-dc2e-44cf-e67e-761230b8d81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "for k in range(1, len(X_train.columns)+1):\n",
        "    print(f'{k} features')\n",
        "    \n",
        "    selector = SelectKBest(k=k)\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_selected, y_train)\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    print(f'Test Mean Absolute Error: ${mae:,.0f} \\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 features\n",
            "Test Mean Absolute Error: $890 \n",
            "\n",
            "2 features\n",
            "Test Mean Absolute Error: $826 \n",
            "\n",
            "3 features\n",
            "Test Mean Absolute Error: $826 \n",
            "\n",
            "4 features\n",
            "Test Mean Absolute Error: $743 \n",
            "\n",
            "5 features\n",
            "Test Mean Absolute Error: $732 \n",
            "\n",
            "6 features\n",
            "Test Mean Absolute Error: $714 \n",
            "\n",
            "7 features\n",
            "Test Mean Absolute Error: $714 \n",
            "\n",
            "8 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "9 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "10 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "11 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "12 features\n",
            "Test Mean Absolute Error: $711 \n",
            "\n",
            "13 features\n",
            "Test Mean Absolute Error: $709 \n",
            "\n",
            "14 features\n",
            "Test Mean Absolute Error: $708 \n",
            "\n",
            "15 features\n",
            "Test Mean Absolute Error: $706 \n",
            "\n",
            "16 features\n",
            "Test Mean Absolute Error: $705 \n",
            "\n",
            "17 features\n",
            "Test Mean Absolute Error: $704 \n",
            "\n",
            "18 features\n",
            "Test Mean Absolute Error: $705 \n",
            "\n",
            "19 features\n",
            "Test Mean Absolute Error: $679 \n",
            "\n",
            "20 features\n",
            "Test Mean Absolute Error: $679 \n",
            "\n",
            "21 features\n",
            "Test Mean Absolute Error: $679 \n",
            "\n",
            "22 features\n",
            "Test Mean Absolute Error: $676 \n",
            "\n",
            "23 features\n",
            "Test Mean Absolute Error: $683 \n",
            "\n",
            "24 features\n",
            "Test Mean Absolute Error: $683 \n",
            "\n",
            "25 features\n",
            "Test Mean Absolute Error: $683 \n",
            "\n",
            "26 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "27 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "28 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "29 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "30 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "31 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "32 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "33 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "34 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "35 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CB3cK1HytGDl",
        "colab_type": "code",
        "outputId": "3f4aabee-b2d8-49ac-a7cf-057f65809d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "training = []\n",
        "testing = []\n",
        "ks = range(1, len(X_train.columns)+1)\n",
        "for k in range(1, len(X_train.columns)+1):\n",
        "    print(f'{k} features')\n",
        "    \n",
        "    selector = SelectKBest(k=k)\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_selected, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_train_selected)\n",
        "    mae = mean_absolute_error(y_train, y_pred)\n",
        "    training.append(mae)\n",
        "\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    testing.append(mae)\n",
        "    print(f'Test Mean Absolute Error: ${mae:,.0f} \\n')\n",
        "\n",
        "plt.plot(ks, training, label='Training Score', color='b')\n",
        "plt.plot(ks, testing, label='Testing Score', color='g')\n",
        "plt.ylabel(\"Mean Absolute Error ($)\")\n",
        "plt.xlabel(\"Number of Features\")\n",
        "plt.title(\"Validation Curve\")\n",
        "plt.legend()\n",
        "# plt.axvline(4,color='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 features\n",
            "Test Mean Absolute Error: $890 \n",
            "\n",
            "2 features\n",
            "Test Mean Absolute Error: $826 \n",
            "\n",
            "3 features\n",
            "Test Mean Absolute Error: $826 \n",
            "\n",
            "4 features\n",
            "Test Mean Absolute Error: $743 \n",
            "\n",
            "5 features\n",
            "Test Mean Absolute Error: $732 \n",
            "\n",
            "6 features\n",
            "Test Mean Absolute Error: $714 \n",
            "\n",
            "7 features\n",
            "Test Mean Absolute Error: $714 \n",
            "\n",
            "8 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "9 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "10 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "11 features\n",
            "Test Mean Absolute Error: $713 \n",
            "\n",
            "12 features\n",
            "Test Mean Absolute Error: $711 \n",
            "\n",
            "13 features\n",
            "Test Mean Absolute Error: $709 \n",
            "\n",
            "14 features\n",
            "Test Mean Absolute Error: $708 \n",
            "\n",
            "15 features\n",
            "Test Mean Absolute Error: $706 \n",
            "\n",
            "16 features\n",
            "Test Mean Absolute Error: $705 \n",
            "\n",
            "17 features\n",
            "Test Mean Absolute Error: $704 \n",
            "\n",
            "18 features\n",
            "Test Mean Absolute Error: $705 \n",
            "\n",
            "19 features\n",
            "Test Mean Absolute Error: $679 \n",
            "\n",
            "20 features\n",
            "Test Mean Absolute Error: $679 \n",
            "\n",
            "21 features\n",
            "Test Mean Absolute Error: $679 \n",
            "\n",
            "22 features\n",
            "Test Mean Absolute Error: $676 \n",
            "\n",
            "23 features\n",
            "Test Mean Absolute Error: $683 \n",
            "\n",
            "24 features\n",
            "Test Mean Absolute Error: $683 \n",
            "\n",
            "25 features\n",
            "Test Mean Absolute Error: $683 \n",
            "\n",
            "26 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "27 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "28 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "29 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "30 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "31 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "32 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "33 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "34 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n",
            "35 features\n",
            "Test Mean Absolute Error: $684 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQZ76k9AtGDm",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "In your assignment, you will do feature selection with SelectKBest.\n",
        "\n",
        "You'll go back to our other New York City real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices. But not just for condos in Tribeca. Instead, you'll predict property sales prices for One Family Dwellings, where the sale price was more than 100 thousand and less than 2 million.\n",
        "\n",
        "If you run the above code cell with your assignment dataset, you will probably get some shocking results like these:\n",
        "\n",
        "```\n",
        "1 features\n",
        "Test MAE: $183,641 \n",
        "\n",
        "2 features\n",
        "Test MAE: $182,569 \n",
        "\n",
        "3 features\n",
        "Test MAE: $182,569 \n",
        "\n",
        "4 features\n",
        "Test MAE: $183,441 \n",
        "\n",
        "5 features\n",
        "Test MAE: $186,532 \n",
        "\n",
        "6 features\n",
        "Test MAE: $176,121 \n",
        "\n",
        "7 features\n",
        "Test MAE: $177,001 \n",
        "\n",
        "8 features\n",
        "Test MAE: $176,707 \n",
        "\n",
        "9 features\n",
        "Test MAE: $170,969 \n",
        "\n",
        "10 features\n",
        "Test MAE: $170,977 \n",
        "\n",
        "11 features\n",
        "Test MAE: $170,507 \n",
        "\n",
        "12 features\n",
        "Test MAE: $162,301 \n",
        "\n",
        "13 features\n",
        "Test MAE: $163,559 \n",
        "\n",
        "14 features\n",
        "Test MAE: $162,562 \n",
        "\n",
        "15 features\n",
        "Test MAE: $162,550 \n",
        "\n",
        "16 features\n",
        "Test MAE: $162,678 \n",
        "\n",
        "17 features\n",
        "Test MAE: $162,419 \n",
        "\n",
        "18 features\n",
        "Test MAE: $162,177 \n",
        "\n",
        "19 features\n",
        "Test MAE: $162,177 \n",
        "\n",
        "20 features\n",
        "Test MAE: $157,893 \n",
        "\n",
        "21 features\n",
        "Test MAE: $157,966 \n",
        "\n",
        "22 features\n",
        "Test MAE: $157,966 \n",
        "\n",
        "23 features\n",
        "Test MAE: $157,966 \n",
        "\n",
        "24 features\n",
        "Test MAE: $157,630 \n",
        "\n",
        "25 features\n",
        "Test MAE: $157,580 \n",
        "\n",
        "26 features\n",
        "Test MAE: $25,968,990,575,776,280 \n",
        "\n",
        "27 features\n",
        "Test MAE: $157,550 \n",
        "\n",
        "28 features\n",
        "Test MAE: $87,300,193,986,380,608 \n",
        "\n",
        "29 features\n",
        "Test MAE: $158,491 \n",
        "\n",
        "30 features\n",
        "Test MAE: $17,529,140,644,990,770 \n",
        "\n",
        "31 features\n",
        "Test MAE: $24,191,458,933,688,856 \n",
        "\n",
        "32 features\n",
        "Test MAE: $15,214,122,471,992,104 \n",
        "\n",
        "33 features\n",
        "Test MAE: $15,539,731,847,001,626 \n",
        "\n",
        "34 features\n",
        "Test MAE: $26,823,915,969,200,480 \n",
        "\n",
        "35 features\n",
        "Test MAE: $3,813,290,272,870,121 \n",
        "\n",
        "36 features\n",
        "Test MAE: $157,900 \n",
        "\n",
        "37 features\n",
        "Test MAE: $157,900 \n",
        "\n",
        "38 features\n",
        "Test MAE: $158,911 \n",
        "\n",
        "39 features\n",
        "Test MAE: $9,101,846,282,581,472 \n",
        "\n",
        "40 features\n",
        "Test MAE: $1,424,168,120,777,820 \n",
        "\n",
        "41 features\n",
        "Test MAE: $158,261 \n",
        "\n",
        "42 features\n",
        "Test MAE: $158,261 \n",
        "\n",
        "43 features\n",
        "Test MAE: $4,784,333,158,313,152 \n",
        "\n",
        "44 features\n",
        "Test MAE: $1,329,759,264,341,476 \n",
        "\n",
        "45 features\n",
        "Test MAE: $158,451 \n",
        "\n",
        "46 features\n",
        "Test MAE: $158,450 \n",
        "\n",
        "47 features\n",
        "Test MAE: $158,450 \n",
        "\n",
        "48 features\n",
        "Test MAE: $1,331,383,815,682,658 \n",
        "\n",
        "49 features\n",
        "Test MAE: $1,504,319,420,789,134 \n",
        "\n",
        "50 features\n",
        "Test MAE: $2,285,927,437,866,492\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqjWySSytGDm",
        "colab_type": "text"
      },
      "source": [
        "Why did the error blow up with 26 features? We can look at the coefficients of the selected features:\n",
        "\n",
        "```\n",
        "BLOCK                                                  -97,035\n",
        "ZIP_CODE                                              -152,985\n",
        "COMMERCIAL_UNITS                    -4,115,324,664,197,034,496\n",
        "TOTAL_UNITS                         -2,872,516,607,892,124,160\n",
        "GROSS_SQUARE_FEET                                      123,739\n",
        "BOROUGH_3                                              146,876\n",
        "BOROUGH_4                                              197,262\n",
        "BOROUGH_2                                              -55,917\n",
        "BOROUGH_5                                              -84,107\n",
        "NEIGHBORHOOD_OTHER                                      56,036\n",
        "NEIGHBORHOOD_FLUSHING-NORTH                             63,394\n",
        "NEIGHBORHOOD_FOREST HILLS                               46,411\n",
        "NEIGHBORHOOD_BOROUGH PARK                               29,915\n",
        "TAX_CLASS_AT_PRESENT_1D               -545,831,543,721,722,112\n",
        "BUILDING_CLASS_AT_PRESENT_A5                            -1,673\n",
        "BUILDING_CLASS_AT_PRESENT_A3             5,516,361,218,128,626\n",
        "BUILDING_CLASS_AT_PRESENT_S1         1,735,885,668,110,473,216\n",
        "BUILDING_CLASS_AT_PRESENT_A6           -25,974,113,243,185,788\n",
        "BUILDING_CLASS_AT_PRESENT_A8          -760,608,646,332,801,664\n",
        "BUILDING_CLASS_AT_PRESENT_S0           941,854,072,479,442,176\n",
        "BUILDING_CLASS_AT_TIME_OF_SALE_A5                      -24,599\n",
        "BUILDING_CLASS_AT_TIME_OF_SALE_A3       -5,516,361,218,111,506\n",
        "BUILDING_CLASS_AT_TIME_OF_SALE_S1    4,253,055,231,847,939,072\n",
        "BUILDING_CLASS_AT_TIME_OF_SALE_A6       25,974,113,243,176,404\n",
        "BUILDING_CLASS_AT_TIME_OF_SALE_A8     -541,733,439,448,260,800\n",
        "BUILDING_CLASS_AT_TIME_OF_SALE_S0      990,851,394,820,416,512\n",
        "```\n",
        "\n",
        "These were the coefficients that minimized the sum of squared errors in the training set. But this model has become too complex, with extreme coefficients that can lead to extreme predictions on new unseen data. \n",
        "\n",
        "This linear model needs _regularization._ Ridge Regression to the rescue!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udCWO6KZ_rKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYACF-l4tGDn",
        "colab_type": "text"
      },
      "source": [
        "# Use scikit-learn to fit Ridge Regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PItOJ7EntGDn",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTTueHHctGDn",
        "colab_type": "text"
      },
      "source": [
        "Josh Starmer explains in his [StatQuest video on Ridge Regression:](https://youtu.be/Q81RR3yKn30?t=222)\n",
        "\n",
        "> The main idea behind **Ridge Regression** is to find a new line that _doesn't_ fit the training data as well. In other words, we introduce a small amount of **bias** into how the new line is fit to the data. But in return for that small amount of bias we get a significant drop in **variance.** In other words, by starting with a slightly worse fit Ridge regression can provide better long-term predictions. BAM!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0D9dOTStGDo",
        "colab_type": "text"
      },
      "source": [
        "### OLS vs Mean Baseline vs Ridge\n",
        "\n",
        "Let's see look at some examples.\n",
        "\n",
        "First, here's a famous, tiny dataset  [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet), dataset III:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr8La3fftGDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "anscombe = sns.load_dataset('anscombe').query('dataset==\"III\"')\n",
        "anscombe.plot.scatter('x', 'y');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY35Z6RKtGDq",
        "colab_type": "text"
      },
      "source": [
        "We'll compare:\n",
        "- Ordinary Least Squares Linear Regression\n",
        "- Mean Baseline\n",
        "- Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbdca4bOtGDq",
        "colab_type": "text"
      },
      "source": [
        "#### OLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKB7jVmKtGDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Plot data\n",
        "ax = anscombe.plot.scatter('x', 'y')\n",
        "\n",
        "# Fit linear model\n",
        "ols = LinearRegression()\n",
        "ols.fit(anscombe[['x']], anscombe['y'])\n",
        "\n",
        "# Get linear equation\n",
        "m = ols.coef_[0].round(2)\n",
        "b = ols.intercept_.round(2)\n",
        "title = f'Linear Regression \\n y = {m}x + {b}'\n",
        "\n",
        "# Get predictions\n",
        "anscombe['y_pred'] = ols.predict(anscombe[['x']])\n",
        "\n",
        "# Plot predictions\n",
        "anscombe.plot('x', 'y_pred', ax=ax, title=title);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95arvug7tGDs",
        "colab_type": "text"
      },
      "source": [
        "#### Mean Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFW9xsWptGDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot data\n",
        "ax = anscombe.plot.scatter('x', 'y')\n",
        "\n",
        "# Mean baseline\n",
        "mean = anscombe['y'].mean()\n",
        "anscombe['y_pred'] = mean\n",
        "title = f'Mean Baseline \\n y = 0x + {mean:.2f}'\n",
        "\n",
        "# Plot \"predictions\"\n",
        "anscombe.plot('x', 'y_pred', ax=ax, title=title);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRcZqxLGtGDv",
        "colab_type": "text"
      },
      "source": [
        "#### Ridge Regression\n",
        "\n",
        "With increasing regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7OCh6mVtGDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def ridge_anscombe(alpha):\n",
        "    \"\"\"\n",
        "    Fit & plot a ridge regression model,\n",
        "    with Anscombe Quartet dataset III.\n",
        "\n",
        "    alpha : positive float, regularization strength\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    anscombe = sns.load_dataset('anscombe').query('dataset==\"III\"')\n",
        "\n",
        "    # Plot data\n",
        "    ax = anscombe.plot.scatter('x', 'y')\n",
        "\n",
        "    # Fit linear model\n",
        "    ridge = Ridge(alpha=alpha, normalize=True)\n",
        "    ridge.fit(anscombe[['x']], anscombe['y'])\n",
        "\n",
        "    # Get linear equation\n",
        "    m = ridge.coef_[0].round(2)\n",
        "    b = ridge.intercept_.round(2)\n",
        "    title = f'Ridge Regression, alpha={alpha} \\n y = {m}x + {b}'\n",
        "\n",
        "    # Get predictions\n",
        "    anscombe['y_pred'] = ridge.predict(anscombe[['x']])\n",
        "\n",
        "    # Plot predictions\n",
        "    anscombe.plot('x', 'y_pred', ax=ax, title=title)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "for alpha in range(10):\n",
        "    ridge_anscombe(alpha=alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPDhKjfItGDx",
        "colab_type": "text"
      },
      "source": [
        "When the Ridge Regression has no regularization (`alpha=0`) then it is identical to Ordinary Least Squares Regression.\n",
        "\n",
        "When we increase the regularization, the predictions looks less and less like OLS and more and more like the mean baseline. The predictions are less sensitive to changes in the independent variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd4UlDRItGDx",
        "colab_type": "text"
      },
      "source": [
        "You may ask, how should we decide the amount of regularization?\n",
        "\n",
        "[The StatQuest video answers,](https://youtu.be/Q81RR3yKn30?t=602)\n",
        "\n",
        "> So how do we decide what value to give lambda? We just try a bunch of values for lambda, and use cross-validation\n",
        "typically 10-fold cross-validation, to determine which one results in the lowest variance. DOUBLE BAM!!!\n",
        "\n",
        "You'll learn more about cross-validation next sprint. For now, the good news is scikit-learn gives us [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html), \"Ridge regression with built-in cross-validation.\"\n",
        "\n",
        "Also, notice that scikit-learn calls the regularization parameter \"alpha\", but StatQuest calls it \"lambda.\" The greek letters are different, but the concept is the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZM4duAxtGDx",
        "colab_type": "text"
      },
      "source": [
        "Let's try these values for alpha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3fQ65OItGDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H98E_8LwtGDz",
        "colab_type": "text"
      },
      "source": [
        "We'll use [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) to find the best alpha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3wjDXuMtGDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "ridge = RidgeCV(alphas=alphas, normalize=True)\n",
        "ridge.fit(anscombe[['x']], anscombe['y'])\n",
        "ridge.alpha_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnmzCkZ2tGD1",
        "colab_type": "text"
      },
      "source": [
        "The fit looks similar to Ordinary Least Squares Regression, but slightly less influenced by the outlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRQ8Jh7wtGD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot data\n",
        "ax = anscombe.plot.scatter('x', 'y')\n",
        "\n",
        "# Get linear equation\n",
        "m = ridge.coef_[0].round(2)\n",
        "b = ridge.intercept_.round(2)\n",
        "title = f'Ridge Regression, alpha={ridge.alpha_} \\n y = {m}x + {b}'\n",
        "\n",
        "# Get predictions\n",
        "anscombe['y_pred'] = ridge.predict(anscombe[['x']])\n",
        "\n",
        "# Plot predictions\n",
        "anscombe.plot('x', 'y_pred', ax=ax, title=title)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvGUIeuntGD3",
        "colab_type": "text"
      },
      "source": [
        "### NYC, 1 feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVJFZsY5tGD3",
        "colab_type": "text"
      },
      "source": [
        "Let's go back to our other New York City dataset, to demonstrate regularization with Ridge Regresson:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "92taRxE8tGD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "# Try a range of alpha parameters for Ridge Regression.\n",
        "\n",
        "# The scikit-learn docs explain, \n",
        "# alpha : Regularization strength; must be a positive float. Regularization \n",
        "# improves the conditioning of the problem and reduces the variance of the \n",
        "# estimates. Larger values specify stronger regularization.\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
        "\n",
        "for alpha in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]:\n",
        "    \n",
        "    # Fit Ridge Regression model\n",
        "    feature = 'bedrooms'\n",
        "    display(HTML(f'Ridge Regression, with alpha={alpha}'))\n",
        "    model = Ridge(alpha=alpha, normalize=True)\n",
        "    model.fit(X_train[[feature]], y_train)\n",
        "    \n",
        "    # Get Test MAE\n",
        "    y_pred = model.predict(X_test[[feature]])\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    display(HTML(f'Test Mean Absolute Error: ${mae:,.0f}'))\n",
        "    \n",
        "    train.plot.scatter(feature, target, alpha=0.05)\n",
        "    plt.plot(X_test[feature], y_pred)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6nR4AVBtGD5",
        "colab_type": "text"
      },
      "source": [
        "### NYC, multiple features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2_br5T8StGD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for alpha in [0.001, 0.01, 0.1, 1.0, 1, 100.0, 1000.0]:\n",
        "    \n",
        "    # Fit Ridge Regression model\n",
        "    display(HTML(f'Ridge Regression, with alpha={alpha}'))\n",
        "    model = Ridge(alpha=alpha, normalize=True)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Get Test MAE\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    display(HTML(f'Test Mean Absolute Error: ${mae:,.0f}'))\n",
        "    \n",
        "    # Plot coefficients\n",
        "    coefficients = pd.Series(model.coef_, X_train.columns)\n",
        "    plt.figure(figsize=(16,8))\n",
        "    coefficients.sort_values().plot.barh(color='grey')\n",
        "    plt.xlim(-400,700)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmKSgNwdtGD7",
        "colab_type": "text"
      },
      "source": [
        "### Regularization just means \"add bias\"\n",
        "\n",
        "OK, there's a bit more to it than that. But that's the core intuition - the problem is the model working \"too well\", so fix it by making it harder for the model!\n",
        "\n",
        "It may sound strange - a technique that is purposefully \"worse\" - but in certain situations, it can really get results.\n",
        "\n",
        "What's bias? In the context of statistics and machine learning, bias is when a predictive model fails to identify relationships between features and the output. In a word, bias is *underfitting*.\n",
        "\n",
        "We want to add bias to the model because of the [bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) - variance is the sensitivity of a model to the random noise in its training data (i.e. *overfitting*), and bias and variance are naturally (inversely) related. Increasing one will always decrease the other, with regards to the overall generalization error (predictive accuracy on unseen data).\n",
        "\n",
        "Visually, the result looks like this:\n",
        "\n",
        "![Regularization example plot](https://upload.wikimedia.org/wikipedia/commons/0/02/Regularization.svg)\n",
        "\n",
        "The blue line is overfit, using more dimensions than are needed to explain the data and so much of the movement is based on noise and won't generalize well. The green line still fits the data, but is less susceptible to the noise - depending on how exactly we parameterize \"noise\" we may throw out actual correlation, but if we balance it right we keep that signal and greatly improve generalizability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5U451fRtGD7",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "In your assignment, you will fit a Ridge Regression model. You can try Linear Regression too  depending on how many features you select, your errors will probably blow up!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUyZNXfVtGD8",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "For your assignment, we're going back to our other **New York City** real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices.\n",
        "\n",
        "But not just for condos in Tribeca...\n",
        "\n",
        "Instead, predict property sales prices for **One Family Dwellings** (`BUILDING_CLASS_CATEGORY` == `'01 ONE FAMILY DWELLINGS'`). \n",
        "\n",
        "Use a subset of the data where the **sale price was more than \\\\$100 thousand and less than $2 million.** \n",
        "\n",
        "You'll practice all of the module's objectives to build your best model yet!"
      ]
    }
  ]
}