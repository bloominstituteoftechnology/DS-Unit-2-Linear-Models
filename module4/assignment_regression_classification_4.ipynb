{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_regression_classification_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CurtCalledBurt/DS-Unit-2-Regression-Classification/blob/master/module4/assignment_regression_classification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8d72050-036c-47be-d85c-93fa6171d546"
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module4')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 156, done.\u001b[K\n",
            "remote: Total 156 (delta 0), reused 0 (delta 0), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (156/156), 19.30 MiB | 14.23 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Collecting category_encoders==2.0.0 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.8MB/s \n",
            "\u001b[?25hCollecting eli5==0.10.0 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ea/47bd5844bb609d45821114aa7e0bc9e4422053fe24a6cf6b357f0d3f74d3/eli5-0.10.0-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 33.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Collecting pandas-profiling==2.3.0 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 47.9MB/s \n",
            "\u001b[?25hCollecting pdpbox==0.2.0 (from -r requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/23/ac7da5ba1c6c03a87c412e7e7b6e91a10d6ecf4474906c3e736f93940d49/PDPbox-0.2.0.tar.gz (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Collecting shap==0.29.3 (from -r requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/82/bab67238ac27d53214b12f6ed095493dc7b43be07c615b8b0dbb7da33157/shap-0.29.3.tar.gz (230kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels==0.10.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.10.1)\n",
            "Requirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.90)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.0->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.0->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.0->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.0->-r requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.0->-r requirements.txt (line 2)) (0.8.5)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.0->-r requirements.txt (line 2)) (3.7.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 44.3MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.29.3->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.29.3->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.29.3->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.0->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Collecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.3)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/46/903ea822d83187bb8b354fcb3d085fb10b7787be39f9cf1628bc6ef8f9c9/pytest-5.2.0-py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.29.3->-r requirements.txt (line 9)) (1.0.16)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.29.3->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.29.3->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.29.3->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.29.3->-r requirements.txt (line 9)) (4.3.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.29.3->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.29.3->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.29.3->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.29.3->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.29.3->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.29.3->-r requirements.txt (line 9)) (4.3.0)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/ed/1cb8e7b85a31807aa0bff8b3e60935370bed7e141df8b530aac6352bddff/pylint-2.4.2-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.23)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.29.3->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.29.3->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.29.3->-r requirements.txt (line 9)) (0.46)\n",
            "Collecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.9MB/s \n",
            "\u001b[?25hCollecting astroid<2.4,>=2.3.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/e1/74a63c85c501c29c52da5be604c025e368f4dd77daf1fa13c878a33e5a36/astroid-2.3.1-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: wrapt==1.11.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n",
            "Collecting lazy-object-proxy==1.4.* (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 16.2MB/s \n",
            "\u001b[?25hCollecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 30.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pandas-profiling, pdpbox, shap, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=0088b7fa026190af88802e9bee715e074667c835912f8d618f2704e95a063a34\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdpbox: filename=PDPbox-0.2.0-cp36-none-any.whl size=57690723 sha256=f1b324f8b60601977a29e7a322eccbd921191c94530cdde50919c7837140df34\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/08/51/63fd122b04a2c87d780464eeffb94867c75bd96a64d500a3fe\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.29.3-cp36-cp36m-linux_x86_64.whl size=344727 sha256=78ed126230215384b0f43143047d5d66e8af1d1d70f3dd7c9f1e92e09e4c5f05\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/20/87/d199e4d7397997f5494e4098104f91313ac8120753bee7b032\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=df639c75279e89a28e44ea6a6b4a141ecfacefd69e316b12daac4d3d863a54c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17486 sha256=60a03ee2b698a9105e822a626fdf3878f09df66b0d6188a8c28ed6383b521ab1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling pdpbox shap htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, eli5, htmlmin, mccabe, isort, lazy-object-proxy, typed-ast, astroid, pylint, pluggy, pytest, pytest-pylint, phik, confuse, pandas-profiling, pdpbox, shap\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.3.1 category-encoders-2.0.0 confuse-1.0.0 eli5-0.10.0 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.2 mccabe-0.6.1 pandas-profiling-2.3.0 pdpbox-0.2.0 phik-0.9.8 pluggy-0.13.0 pylint-2.4.2 pytest-5.2.0 pytest-pylint-0.14.1 shap-0.29.3 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipBYS77PUwNR",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "colab": {}
      },
      "source": [
        "# Read the Tanzania Waterpumps data\n",
        "# train_features.csv : the training set features\n",
        "# train_labels.csv : the training set labels\n",
        "# test_features.csv : the test set features\n",
        "# sample_submission.csv : a sample submission file in the correct format\n",
        "    \n",
        "import pandas as pd\n",
        "\n",
        "train_features = pd.read_csv('../data/waterpumps/train_features.csv')\n",
        "train_labels = pd.read_csv('../data/waterpumps/train_labels.csv')\n",
        "test_features = pd.read_csv('../data/waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/waterpumps/sample_submission.csv')\n",
        "\n",
        "assert train_features.shape == (59400, 40)\n",
        "assert train_labels.shape == (59400, 2)\n",
        "assert test_features.shape == (14358, 40)\n",
        "assert sample_submission.shape == (14358, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 4\n",
        "\n",
        "\n",
        "## Assignment\n",
        "\n",
        "- [ ] Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "- [ ] [Sign up for a Kaggle account](https://www.kaggle.com/), if you don’t already have one. Go to our Kaggle InClass competition website. You will be given the URL in Slack. Go to the Rules page. Accept the rules of the competition.\n",
        "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your validation accuracy score.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Clean the data. For ideas, refer to [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide),  a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding. For example, you could try `quantity`, `basin`, `extraction_type_class`, and more. (But remember it may not work with high cardinality categoricals.)\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html).\n",
        "\n",
        "---\n",
        "\n",
        "## Data Dictionary \n",
        "\n",
        "### Features\n",
        "\n",
        "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided the following set of information about the waterpoints:\n",
        "\n",
        "- `amount_tsh` : Total static head (amount water available to waterpoint)\n",
        "- `date_recorded` : The date the row was entered\n",
        "- `funder` : Who funded the well\n",
        "- `gps_height` : Altitude of the well\n",
        "- `installer` : Organization that installed the well\n",
        "- `longitude` : GPS coordinate\n",
        "- `latitude` : GPS coordinate\n",
        "- `wpt_name` : Name of the waterpoint if there is one\n",
        "- `num_private` :  \n",
        "- `basin` : Geographic water basin\n",
        "- `subvillage` : Geographic location\n",
        "- `region` : Geographic location\n",
        "- `region_code` : Geographic location (coded)\n",
        "- `district_code` : Geographic location (coded)\n",
        "- `lga` : Geographic location\n",
        "- `ward` : Geographic location\n",
        "- `population` : Population around the well\n",
        "- `public_meeting` : True/False\n",
        "- `recorded_by` : Group entering this row of data\n",
        "- `scheme_management` : Who operates the waterpoint\n",
        "- `scheme_name` : Who operates the waterpoint\n",
        "- `permit` : If the waterpoint is permitted\n",
        "- `construction_year` : Year the waterpoint was constructed\n",
        "- `extraction_type` : The kind of extraction the waterpoint uses\n",
        "- `extraction_type_group` : The kind of extraction the waterpoint uses\n",
        "- `extraction_type_class` : The kind of extraction the waterpoint uses\n",
        "- `management` : How the waterpoint is managed\n",
        "- `management_group` : How the waterpoint is managed\n",
        "- `payment` : What the water costs\n",
        "- `payment_type` : What the water costs\n",
        "- `water_quality` : The quality of the water\n",
        "- `quality_group` : The quality of the water\n",
        "- `quantity` : The quantity of water\n",
        "- `quantity_group` : The quantity of water\n",
        "- `source` : The source of the water\n",
        "- `source_type` : The source of the water\n",
        "- `source_class` : The source of the water\n",
        "- `waterpoint_type` : The kind of waterpoint\n",
        "- `waterpoint_type_group` : The kind of waterpoint\n",
        "\n",
        "### Labels\n",
        "\n",
        "There are three possible values:\n",
        "\n",
        "- `functional` : the waterpoint is operational and there are no repairs needed\n",
        "- `functional needs repair` : the waterpoint is operational, but needs repairs\n",
        "- `non functional` : the waterpoint is not operational\n",
        "\n",
        "--- \n",
        "\n",
        "## Generate a submission\n",
        "\n",
        "Your code to generate a submission file may look like this:\n",
        "\n",
        "```python\n",
        "# estimator is your model or pipeline, which you've fit on X_train\n",
        "\n",
        "# X_test is your pandas dataframe or numpy array, \n",
        "# with the same number of rows, in the same order, as test_features.csv, \n",
        "# and the same number of columns, in the same order, as X_train\n",
        "\n",
        "y_pred = estimator.predict(X_test)\n",
        "\n",
        "\n",
        "# Makes a dataframe with two columns, id and status_group, \n",
        "# and writes to a csv file, without the index\n",
        "\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('your-submission-filename.csv', index=False)\n",
        "```\n",
        "\n",
        "If you're working locally, the csv file is saved in the same directory as your notebook.\n",
        "\n",
        "If you're using Google Colab, you can use this code to download your submission csv file.\n",
        "\n",
        "```python\n",
        "from google.colab import files\n",
        "files.download('your-submission-filename.csv')\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GIxriwFK-S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3YEMo4nAkjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking if this is a functioning dataframe; it is\n",
        "train_features;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wMRh0WrHfbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking what datatypes we have, see if there's \n",
        "# anything categorical we need to worry about\n",
        "train_features.dtypes;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g15mrpgEHru-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking for NaN's, there's a lot, but we'll deal with them later\n",
        "train_features.isna().sum();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHWO_WlBQF14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes the features of a train and test set in a pandas dataframe. \n",
        "# Remove the target column before putting the features in here.\n",
        "# returns the feature columns as a pandas dataframe one-hot-encoded\n",
        "\n",
        "# specify which of a test or trian set you are putting in!\n",
        "def one_hot_encode(train_features, test_features, max_cardinality=50):\n",
        "  # necessary imports\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import category_encoders as ce\n",
        "  \n",
        "  # create the one_hot_encoder\n",
        "  encoder = ce.OneHotEncoder(use_cat_names = True)\n",
        "  \n",
        "  #determine which categorical features are appropriate to one-hot-encode\n",
        "  numerics = train_features.select_dtypes(include='number').columns.tolist()\n",
        "  categoricals = train_features.select_dtypes(exclude='number').columns.tolist()\n",
        "  low_cardinality = [col for col in categoricals if train_features[col].nunique() <= max_cardinality]\n",
        "  features = numerics + low_cardinality\n",
        "  \n",
        "  #create a shortened dataframe of numeric features and categorical features with low cardinality\n",
        "  train_features = train_features[features]\n",
        "  test_features = test_features[features]\n",
        "  \n",
        "  # ALWAYS .fit_transform on TRAIN data set\n",
        "  # ALWAYS .transform on TEST data set\n",
        "  train_features_encoded = encoder.fit_transform(train_features)\n",
        "  test_features_encoded = encoder.transform(test_features)\n",
        "  \n",
        "  return train_features_encoded, test_features_encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EBStlOWUulu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calling the one-hot-encode function on our train and test features dataframes\n",
        "train_features_encoded, test_features_encoded = one_hot_encode(train_features, test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Amxyx3xphbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cc89479-21d4-425e-f258-9ced7a94124a"
      },
      "source": [
        "# train, val, test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, val_x = train_test_split(train_features_encoded, random_state = 20392)\n",
        "train_y, val_y = train_test_split(train_labels, random_state = 20392)\n",
        "\n",
        "\n",
        "train_x.shape, val_x.shape, train_y.shape, val_y.shape"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((44550, 186), (14850, 186), (44550, 2), (14850, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF4RqDQtBI84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making sure the x and y sets match up correctly\n",
        "train_x.head();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bzHrA40BwGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y.head();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhA4TpaIBx9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "130508a5-c61d-409c-ad1f-0edddb8880c0"
      },
      "source": [
        "# getting a sense of how much accuracy our baseline model should have\n",
        "train_labels['status_group'].value_counts(normalize=True)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functional                 0.543081\n",
              "non functional             0.384242\n",
              "functional needs repair    0.072677\n",
              "Name: status_group, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-7r131tOC4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes the column of a train_label dataframe\n",
        "# prints the accuracy of the baseline\n",
        "# returns the baseline list\n",
        "\n",
        "def baseline_Logistic(labels):\n",
        "  # making a list of the same size as 'labels' \n",
        "  # with only the mode as the only possible entree\n",
        "  most_common_label = labels.mode()[0]\n",
        "  pred_baseline = [most_common_label] * len(labels)\n",
        "  \n",
        "  #calculate baseline accuracy\n",
        "  wrong_count = 0\n",
        "  for i in range(len(pred_baseline)):\n",
        "    if pred_baseline[i] != train_labels['status_group'][i]:\n",
        "      wrong_count += 1\n",
        "  acc = 1 - wrong_count / len(pred_baseline)\n",
        "  \n",
        "  print('Accuracy of Baseline: ', acc*100, '%')\n",
        "  return(pred_baseline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0qYcMm6PJke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef85c377-9ace-4ee5-e1a3-8fbdb3e0f608"
      },
      "source": [
        "# calling the baseline function to get the baseline accuracy\n",
        "pred_baseline = baseline_Logistic(train_labels['status_group'])"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Baseline:  54.3080808080808 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSpohOpJJ1pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "154747d0-e88c-40e7-d0c5-3f8c1364c188"
      },
      "source": [
        "#on to Logistic Regression!\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_reg = LogisticRegression(solver='lbfgs',  multi_class='multinomial', max_iter=10000)\n",
        "\n",
        "logistic_reg.fit(train_x, train_y['status_group'])"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
              "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV54M-83XWkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a64f08d7-8756-43b1-c58c-3801e7754153"
      },
      "source": [
        "print('Validation Accuracy', logistic_reg.score(val_x, val_y['status_group']))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.6963636363636364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTg-rVqUsZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate submission\n",
        "\n",
        "# estimator is your model or pipeline, which you've fit on X_train\n",
        "\n",
        "# X_test is your pandas dataframe or numpy array, \n",
        "# with the same number of rows, in the same order, as test_features.csv, \n",
        "# and the same number of columns, in the same order, as X_train\n",
        "\n",
        "\n",
        "# y_pred is an array, we make it into a column in our submission dataframe next\n",
        "y_pred = logistic_reg.predict(test_features_encoded)\n",
        "\n",
        "# Makes a dataframe with two columns, id and status_group, \n",
        "# and writes to a csv file, without the index\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('Curtis-McKendrick-Pipes.csv', index=False)\n",
        "# If you're working locally, the csv file is saved in the same directory as your notebook.\n",
        "\n",
        "\n",
        "# If you're using Google Colab, you can use this code to download your submission csv file.\n",
        "# from google.colab import files\n",
        "# files.download('module4/Curtis-McKendrick-Pipes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h7Eo2PDuUAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ad9a8c68-a16c-487b-dade-322da2f44dc8"
      },
      "source": [
        "# make sure the y_pred entrees overwrite the status_group column\n",
        "# of the submission correctly\n",
        "y_pred[:5]"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['non functional', 'functional', 'non functional', 'non functional',\n",
              "       'functional'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veDXcd6GksVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "33cb6fa5-f941-455d-c637-3e81281ee134"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50785</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51630</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17168</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45559</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49871</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id    status_group\n",
              "0  50785  non functional\n",
              "1  51630      functional\n",
              "2  17168  non functional\n",
              "3  45559  non functional\n",
              "4  49871      functional"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BePp6nm_ksfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}