{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chris Huskey - Sprint_Challenge - DS_Unit_2_Sprint_1 - Linear_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrishuskey/DS-Unit-2-Linear-Models/blob/master/Chris_Huskey_Sprint_Challenge_DS_Unit_2_Sprint_1_Linear_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VZf2akBaMjq8"
      },
      "source": [
        "_Lambda School Data Science, Unit 2_\n",
        " \n",
        "# Linear Models Sprint Challenge\n",
        "\n",
        "To demonstrate mastery on your Sprint Challenge, do all the required, numbered instructions in this notebook.\n",
        "\n",
        "To earn a score of \"3\", also do all the stretch goals.\n",
        "\n",
        "You are permitted and encouraged to do as much data exploration as you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20OITf58NLQh"
      },
      "source": [
        "### Part 1, Classification\n",
        "- 1.1. Do train/test split. Arrange data into X features matrix and y target vector\n",
        "- 1.2. Use scikit-learn to fit a logistic regression model\n",
        "- 1.3. Report classification metric: accuracy\n",
        "\n",
        "### Part 2, Regression\n",
        "- 2.1. Begin with baselines for regression\n",
        "- 2.2. Do train/validate/test split\n",
        "- 2.3. Arrange data into X features matrix and y target vector\n",
        "- 2.4. Do one-hot encoding\n",
        "- 2.5. Use scikit-learn to fit a linear regression or ridge regression model\n",
        "- 2.6. Report validation MAE and $R^2$\n",
        "\n",
        "### Stretch Goals, Regression\n",
        "- Make at least 2 visualizations to explore relationships between features and target. You may use any visualization library\n",
        "- Try at least 3 feature combinations. You may select features manually, or automatically\n",
        "- Report validation MAE and $R^2$ for each feature combination you try\n",
        "- Report test MAE and $R^2$ for your final model\n",
        "- Print or plot the coefficients for the features in your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BxoFSeX5OX5k",
        "outputId": "18fc5779-5857-4f87-ffe3-fafc80030a9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# If you're in Colab...\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "    !pip install plotly==4.*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders==2.* in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.10.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.17.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.21.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.25.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders==2.*) (1.12.0)\n",
            "Requirement already satisfied: pandas-profiling==2.* in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.4.2)\n",
            "Requirement already satisfied: phik>=0.9.8 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.9.8)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.25.2)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.0.0)\n",
            "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (2.10.3)\n",
            "Requirement already satisfied: matplotlib>=1.4 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (3.1.1)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (3.0.5)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.1.12)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from missingno>=0.4.2->pandas-profiling==2.*) (0.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from missingno>=0.4.2->pandas-profiling==2.*) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from missingno>=0.4.2->pandas-profiling==2.*) (1.17.3)\n",
            "Requirement already satisfied: pytest>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.*) (5.2.2)\n",
            "Requirement already satisfied: pytest-pylint>=0.13.0 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.*) (0.14.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.*) (5.3.4)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.*) (5.6.1)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.*) (0.40.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas-profiling==2.*) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pandas-profiling==2.*) (2.6.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.*) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.8->pandas-profiling==2.*) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling==2.*) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling==2.*) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4->pandas-profiling==2.*) (2.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (0.23)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (1.8.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (7.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (0.1.7)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (0.13.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (1.12.0)\n",
            "Requirement already satisfied: pylint>=1.4.5 in /usr/local/lib/python3.6/dist-packages (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (2.4.3)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.*) (4.6.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.*) (4.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.*) (17.0.0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.*) (4.3.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (3.1.0)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (4.4.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (0.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (2.1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.*) (0.30.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas-profiling==2.*) (41.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: astroid<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (2.3.2)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (0.6.1)\n",
            "Requirement already satisfied: isort<5,>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (4.3.21)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.*) (4.4.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets->jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.*) (0.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (0.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.*) (2.6.0)\n",
            "Requirement already satisfied: lazy-object-proxy==1.4.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (1.4.3)\n",
            "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (1.4.0)\n",
            "Requirement already satisfied: wrapt==1.11.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.*) (1.11.2)\n",
            "Requirement already satisfied: plotly==4.* in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.*) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.*) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q7u1KtsnOi78"
      },
      "source": [
        "# Part 1, Classification: Predict Blood Donations üöë\n",
        "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive.\n",
        "\n",
        "The goal is to predict whether the donor made a donation in March 2007, using information about each donor's history.\n",
        "\n",
        "Good data-driven systems for tracking and predicting donations and supply needs can improve the entire supply chain, making sure that more patients get the blood transfusions they need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJzpgv-fO4rh",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "donors = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
        "assert donors.shape == (748,5)\n",
        "\n",
        "donors = donors.rename(columns={\n",
        "    'Recency (months)': 'months_since_last_donation', \n",
        "    'Frequency (times)': 'number_of_donations', \n",
        "    'Monetary (c.c. blood)': 'total_volume_donated', \n",
        "    'Time (months)': 'months_since_first_donation', \n",
        "    'whether he/she donated blood in March 2007': 'made_donation_in_march_2007'\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JOCqi_5JOLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Split into not_test and test sets:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "working_data, test = train_test_split(donors, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmmQfbjNNa7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data prep.:  Function to do data prep. on each set:\n",
        "def data_prep(dataframes):\n",
        "  for dataframe in dataframes:\n",
        "    dataframe['avg_donations_per_month'] = dataframe['number_of_donations'] / dataframe['months_since_first_donation']\n",
        "    # What other data prep. to do?  TBH just not sure how to approach this problem yet -- need to think about it for a second, but no time left... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d9EMq27Wml3",
        "colab_type": "code",
        "outputId": "920826f0-a13c-491d-9e56-cbda0abb4fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Run data prep. for each dataset, after split into working_data vs. test, \n",
        "# but before we split working_data into train and val matrices and target vectors:\n",
        "data_prep([working_data, test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DER7rlm4I86g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['months_since_last_donation', 'number_of_donations', 'months_since_first_donation']  # 'months_since_last_donation', 'number_of_donations', 'months_since_first_donation', 'avg_donations_per_month'\n",
        "target = 'made_donation_in_march_2007'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Art7U6LtTlJz",
        "colab_type": "text"
      },
      "source": [
        "# Baseline:  Majority Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UdYU6IOTqye",
        "colab_type": "code",
        "outputId": "92373379-438e-4065-8f46-7585675874f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "donors[target].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    570\n",
              "1    178\n",
              "Name: made_donation_in_march_2007, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBDznTtgUHRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "majority_class = donors[target].mode()[0]  # == donors['made_donation_in_march_2007'].value_counts().idxmax()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsprqUDoUCRN",
        "colab_type": "code",
        "outputId": "c2f18574-e26a-440b-c250-48122ab008f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Baseline Accuracy and Recall:  Dummy Model (Majority Classifier) Accuracy:\n",
        "y_true_dummy_classifier = working_data[target]\n",
        "y_pred_dummy_classifier = [majority_class] * len(working_data[target])\n",
        "print('Baseline:  Dummy Model Majority Classifier Performance:\\n')\n",
        "print(f'Accuracy: {accuracy_score(y_true_dummy_classifier, y_pred_dummy_classifier):.2f}')\n",
        "print(f'Recall (TP / (TP + FN)): {recall_score(y_true_dummy_classifier, y_pred_dummy_classifier):.2f}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline:  Dummy Model Majority Classifier Performance:\n",
            "\n",
            "Accuracy: 0.75\n",
            "Recall (TP / (TP + FN)): 0.00\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl7jLwEDgnkz",
        "colab_type": "code",
        "outputId": "efcc3624-caef-4cb7-f9ca-2350928bf6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# Confusion matrix (normalized):\n",
        "print('Confusion matrix (normalized) for reference:')\n",
        "cm_dummy_classifier = pd.DataFrame(confusion_matrix(y_true_dummy_classifier, y_pred_dummy_classifier), index=['Actual F', 'Actual T'], columns=['Predicted F', 'Predicted T'])\n",
        "assert round((cm_dummy_classifier / cm_dummy_classifier.sum().sum()).sum().sum(), 10) == 1.0\n",
        "cm_dummy_classifier / cm_dummy_classifier.sum().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix (normalized) for reference:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted F</th>\n",
              "      <th>Predicted T</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual F</th>\n",
              "      <td>0.749164</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual T</th>\n",
              "      <td>0.250836</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted F  Predicted T\n",
              "Actual F     0.749164          0.0\n",
              "Actual T     0.250836          0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P66Fpcq1PYZl"
      },
      "source": [
        "## 1.1. Do train/test split. Arrange data into X features matrix and y target vector\n",
        "\n",
        "Do these steps in either order.\n",
        "\n",
        "Use scikit-learn's train/test split function to split randomly. (You can include 75% of the data in the train set, and hold out 25% for the test set, which is the default.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABg1dtxPosb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Split into train and validate sets:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_working_data = pd.DataFrame(data=working_data[features])\n",
        "y_working_data = working_data[target]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_working_data, y_working_data, train_size=0.75)\n",
        "\n",
        "# Check to make sure train + val + test sets add up to the whole dataset:\n",
        "assert X_train.shape[0] + X_val.shape[0] + test.shape[0] == donors.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ln9fqAghRmQT"
      },
      "source": [
        "## 1.2. Use scikit-learn to fit a logistic regression model\n",
        "\n",
        "You may use any number of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiQ47ZUzEC-z",
        "colab_type": "code",
        "outputId": "148b6306-d20e-4d2b-dcc4-c7583a3a7913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 1. Import estimator class:\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# 2. Instantiate the estimator class:\n",
        "log_reg = LogisticRegressionCV(cv=StratifiedKFold(n_splits=5), scoring='accuracy', solver='lbfgs', n_jobs=-1, random_state=42)  # max_iter=100 if takes too long\n",
        "# not converging, regardless of which solver I use...\n",
        "\n",
        "# 3. Make X feature matrices and y target vectors:\n",
        "# Did this above\n",
        "\n",
        "# Encode / impute missing values / scale if needed:\n",
        "\n",
        "# Encode:\n",
        "\n",
        "# Impute:\n",
        "# Not needed, because no missing/NaN values\n",
        "\n",
        "# Scale:\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# 4. Fit the model to our training data:\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Training set accuracy:\n",
        "y_true_train = y_train\n",
        "y_pred_train = log_reg.predict(X_train_scaled)\n",
        "print('Model performance on training set:\\n')\n",
        "print(f'Training set accuracy: {accuracy_score(y_true_train, y_pred_train):.2f}')\n",
        "print(f'Training set recall (TP / (TP + FN)): {recall_score(y_true_train, y_pred_train):.2f}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance on training set:\n",
            "\n",
            "Training set accuracy: 0.77\n",
            "Training set recall (TP / (TP + FN)): 0.19\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcb-ktVHguQj",
        "colab_type": "code",
        "outputId": "284cda01-4066-4db8-a67e-77c2c0393fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# Confusion matrix (normalized):\n",
        "print('Confusion matrix (normalized) for reference:')\n",
        "cm_train = pd.DataFrame(confusion_matrix(y_true_train, y_pred_train), index=['Actual F', 'Actual T'], columns=['Predicted F', 'Predicted T'])\n",
        "assert round((cm_train / cm_train.sum().sum()).sum().sum(), 10) == 1.0\n",
        "cm_train / cm_train.sum().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix (normalized) for reference:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted F</th>\n",
              "      <th>Predicted T</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual F</th>\n",
              "      <td>0.723214</td>\n",
              "      <td>0.024554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual T</th>\n",
              "      <td>0.205357</td>\n",
              "      <td>0.046875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted F  Predicted T\n",
              "Actual F     0.723214     0.024554\n",
              "Actual T     0.205357     0.046875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ah6EhiRVSusy"
      },
      "source": [
        "## 1.3. Report classification metric: accuracy\n",
        "\n",
        "What is your model's accuracy on the test set?\n",
        "\n",
        "Don't worry if your model doesn't beat the majority class baseline. That's okay!\n",
        "\n",
        "_\"The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.\"_ ‚Äî[John Tukey](https://en.wikiquote.org/wiki/John_Tukey)\n",
        "\n",
        "(Also, if we used recall score instead of accuracy score, then your model would almost certainly beat the baseline. We'll discuss how to choose and interpret evaluation metrics throughout this unit.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZfJ2NFsASt9_",
        "outputId": "3fd20e64-9341-4376-e4e1-2a26e6762120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# 5. Apply our model to new data:\n",
        "y_true_val = y_val\n",
        "y_pred_val = log_reg.predict(X_val_scaled)\n",
        "print('Model performance on validation set:\\n')\n",
        "print(f'Validation set accuracy: {accuracy_score(y_true_val, y_pred_val):.2f}')\n",
        "print(f'Training set recall (TP / (TP + FN)): {recall_score(y_true_val, y_pred_val):.2f}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model performance on validation set:\n",
            "\n",
            "Validation set accuracy: 0.79\n",
            "Training set recall (TP / (TP + FN)): 0.22\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38x6TjyGhHIc",
        "colab_type": "code",
        "outputId": "780bd8a4-8838-4768-a131-937f9e37f126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# Confusion matrix (normalized):\n",
        "print('Confusion matrix (normalized) for reference:')\n",
        "cm_val = pd.DataFrame(confusion_matrix(y_true_val, y_pred_val), index=['Actual F', 'Actual T'], columns=['Predicted F', 'Predicted T'])\n",
        "assert round((cm_val / cm_val.sum().sum()).sum().sum(), 10) == 1.0\n",
        "cm_val / cm_val.sum().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix (normalized) for reference:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted F</th>\n",
              "      <th>Predicted T</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual F</th>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.013333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual T</th>\n",
              "      <td>0.193333</td>\n",
              "      <td>0.053333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted F  Predicted T\n",
              "Actual F     0.740000     0.013333\n",
              "Actual T     0.193333     0.053333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xDmZn3ApOM7t"
      },
      "source": [
        "# Part 2, Regression: Predict home prices in Ames, Iowa üè†\n",
        "\n",
        "You'll use historical housing data. ***There's a data dictionary at the bottom of the notebook.*** \n",
        "\n",
        "Run this code cell to load the dataset:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBwzD0sRrlGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ptoRG1lu7H4",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "URL = 'https://drive.google.com/uc?export=download&id=1522WlEW6HFss36roD_Cd9nybqSuiVcCK'\n",
        "homes = pd.read_csv(URL)\n",
        "assert homes.shape == (2904, 47)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CowG-cgZ5ZrB"
      },
      "source": [
        "## 2.1. Begin with baselines\n",
        "\n",
        "What is the Mean Absolute Error and R^2 score for a mean baseline? (You can get these estimated scores using all your data, before splitting it.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Py0TZuztA0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baseline:  Dummy Mean Model (same as DummyRegressor(strategy='mean')):\n",
        "y_true_dummy_mean = homes['SalePrice']\n",
        "y_pred_dummy_mean = np.full(len(homes['SalePrice']), homes['SalePrice'].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7clZDeV1uqEI",
        "colab_type": "code",
        "outputId": "e67f7a0f-ee36-4745-c1ea-2bc344e77bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Get error metrics for Dummy Mean Model:\n",
        "print('Baseline:  Dummy Mean Model Error:\\n')\n",
        "print(f'Mean absolute error (MAE): {mean_absolute_error(y_true_dummy_mean, y_pred_dummy_mean):.1f}')\n",
        "mse_dummy_mean = mean_squared_error(y_true_dummy_mean, y_pred_dummy_mean)\n",
        "print(f'Mean squared error (MSE): {mse_dummy_mean:.1f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {sqrt(mse_dummy_mean):.1f}')\n",
        "print(f'R^2 score: {r2_score(y_true_dummy_mean, y_pred_dummy_mean):.2f}\\n')  # Should be 0 because y = mean line has no variance"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline:  Dummy Mean Model Error:\n",
            "\n",
            "Mean absolute error (MAE): 58149.9\n",
            "Mean squared error (MSE): 6366297661.5\n",
            "Root Mean Squared Error (RMSE): 79789.1\n",
            "R^2 score: 0.00\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yqeiq1wvyrTq"
      },
      "source": [
        "## 2.2. Do train/validate/test split\n",
        "\n",
        "Train on houses sold in the years 2006 - 2008. (1,920 rows)\n",
        "\n",
        "Validate on house sold in 2009. (644 rows)\n",
        "\n",
        "Test on houses sold in 2010. (340 rows)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WKFjWLI3w0P_",
        "colab": {}
      },
      "source": [
        "# Train/validate/test split:\n",
        "train = homes[homes['Yr_Sold'] <= 2008]\n",
        "val = homes[homes['Yr_Sold'] == 2009]\n",
        "test = homes[homes['Yr_Sold'] == 2010]\n",
        "\n",
        "# Check to make sure we included all observations from the original data set:\n",
        "assert train.shape[0] + val.shape[0] + test.shape[0] == homes.Yr_Sold.value_counts(dropna=False).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7BXgJdmyuKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data prep.:  Function to do all our data prep. on each set:\n",
        "def data_prep(dataframes):\n",
        "  for dataframe in dataframes:\n",
        "    dataframe['Years_Since_Renovated'] = dataframe['Yr_Sold'] - dataframe['Year_Remod/Add']  # ['Year_Remod/Add'] already includes ['Year_Built'] if no renovation after that"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUGNJFCxyyrI",
        "colab_type": "code",
        "outputId": "f8bb3ab7-9258-44a0-c8e0-6a488f860c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Run function:\n",
        "data_prep([train, val, test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hk1bYDJy6txq"
      },
      "source": [
        "## 2.3. Arrange data into X features matrix and y target vector\n",
        "\n",
        "Select at least one numeric feature and at least one categorical feature.\n",
        "\n",
        "Otherwise, you may choose whichever features and however many you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRYfHujO0z4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features = ['Overall_Cond', '1st_Flr_SF', 'Lot_Area', 'Gr_Liv_Area', 'Bedroom_AbvGr', 'Years_Since_Renovated', 'TotRms_AbvGrd', 'Functional']\n",
        "target = 'SalePrice'\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "# # Start:\n",
        "# 'Overall_Cond', \n",
        "# '1st_Flr_SF', \n",
        "# 'Lot_Area', \n",
        "# 'Gr_Liv_Area', \n",
        "# 'Bedroom_AbvGr', \n",
        "# 'Years_Since_Renovated' \n",
        "# 'TotRms_AbvGrd', \n",
        "\n",
        "# # Categorical variable to encode:\n",
        "# 'Functional', \n",
        "\n",
        "# # TBD:\n",
        "# 'Bldg_Type', \n",
        "\n",
        "# 'Full_Bath', \n",
        "# 'Half_Bath', \n",
        "# 'Bsmt_Full_Bath', \n",
        "# 'Bsmt_Half_Bath', \n",
        "\n",
        "# 'House_Style', \n",
        "# 'Kitchen_AbvGr', \n",
        "\n",
        "# 'Sale_Condition', \n",
        "# 'Sale_Type', "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zDT-gSl_-Gwh"
      },
      "source": [
        "## 2.4. Do one-hot encoding\n",
        "\n",
        "Encode your categorical feature(s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHWoFLzF6d2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7BB96u97DDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode categorical variable: ['Functional']:\n",
        "encoder = ce.OneHotEncoder(cols='Functional', use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ZceruUx-Vs-"
      },
      "source": [
        "## 2.5. Use scikit-learn to fit a linear regression or ridge regression model\n",
        "Fit your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kvy4Z0xv7eJF",
        "outputId": "8636cf1c-e529-47fa-ac9d-5e852328c4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# 1. Import estimator class:\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 2. Instantiate the estimator class:\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "# 3. Make X feature matrices and y target vectors:\n",
        "# Did this above\n",
        "\n",
        "# Encode / impute missing values / scale if needed:\n",
        "# Encoded above already\n",
        "# No need to impute, because no missing/NaN values\n",
        "\n",
        "# 4. Fit the model to our training data:\n",
        "lin_reg.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Training set error:\n",
        "# Error on training set:\n",
        "y_true_train = y_train\n",
        "y_pred_train = lin_reg.predict(X_train_encoded)\n",
        "print('Training Set: Model Error:')\n",
        "print(f'MAE: {mean_absolute_error(y_true_train, y_pred_train):.1f}')\n",
        "mse_train = mean_squared_error(y_true_train, y_pred_train)\n",
        "print(f'MSE: {mse_train:.1f}')\n",
        "print(f'RMSE: {sqrt(mse_train):.1f}')\n",
        "print(f'R^2 score: {r2_score(y_true_train, y_pred_train):.2f}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set: Model Error:\n",
            "MAE: 28052.4\n",
            "MSE: 1969842594.3\n",
            "RMSE: 44382.9\n",
            "R^2 score: 0.69\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E9reASgw-i8T"
      },
      "source": [
        "## 2.6. Report validation MAE and $R^2$\n",
        "\n",
        "What is your model's Mean Absolute Error and $R^2$ score on the validation set? (You are not graded on how high or low your validation scores are.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWdozzSzEjO-",
        "colab_type": "code",
        "outputId": "90d243fe-3b65-476b-ef5f-785d88b2d04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# 5. Apply our model to new data:\n",
        "\n",
        "# Error on validation set:\n",
        "y_true_val = y_val\n",
        "y_pred_val = lin_reg.predict(X_val_encoded)\n",
        "print('Validation Set Error:')\n",
        "print(f'MAE: {mean_absolute_error(y_true_val, y_pred_val):.1f}')\n",
        "mse_val = mean_squared_error(y_true_val, y_pred_val)\n",
        "print(f'MSE: {mse_val:.1f}')\n",
        "print(f'RMSE: {sqrt(mse_val):.1f}')\n",
        "print(f'R^2 score: {r2_score(y_true_val, y_pred_val):.2f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Set Error:\n",
            "MAE: 28336.2\n",
            "MSE: 1694441822.3\n",
            "RMSE: 41163.6\n",
            "R^2 score: 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DidByDsrOa-o"
      },
      "source": [
        "# Stretch Goals, Regression\n",
        "- Make at least 2 visualizations to explore relationships between features and target. You may use any visualization library\n",
        "- Try at least 3 feature combinations. You may select features manually, or automatically\n",
        "- Report validation MAE and $R^2$ for each feature combination you try\n",
        "- Report test MAE and $R^2$ for your final model\n",
        "- Print or plot the coefficients for the features in your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xOfSQIf3Y3OV",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PdkjBN1Dy_-A"
      },
      "source": [
        "# Data Dictionary \n",
        "\n",
        "Here's a description of the data fields:\n",
        "\n",
        "```\n",
        "1st_Flr_SF: First Floor square feet\n",
        "\n",
        "Bedroom_AbvGr: Bedrooms above grade (does NOT include basement bedrooms)\n",
        "\n",
        "Bldg_Type: Type of dwelling\n",
        "\t\t\n",
        "       1Fam\tSingle-family Detached\t\n",
        "       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n",
        "       Duplx\tDuplex\n",
        "       TwnhsE\tTownhouse End Unit\n",
        "       TwnhsI\tTownhouse Inside Unit\n",
        "       \n",
        "Bsmt_Half_Bath: Basement half bathrooms\n",
        "\n",
        "Bsmt_Full_Bath: Basement full bathrooms\n",
        "\n",
        "Central_Air: Central air conditioning\n",
        "\n",
        "       N\tNo\n",
        "       Y\tYes\n",
        "\t\t\n",
        "Condition_1: Proximity to various conditions\n",
        "\t\n",
        "       Artery\tAdjacent to arterial street\n",
        "       Feedr\tAdjacent to feeder street\t\n",
        "       Norm\tNormal\t\n",
        "       RRNn\tWithin 200' of North-South Railroad\n",
        "       RRAn\tAdjacent to North-South Railroad\n",
        "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
        "       PosA\tAdjacent to postive off-site feature\n",
        "       RRNe\tWithin 200' of East-West Railroad\n",
        "       RRAe\tAdjacent to East-West Railroad\n",
        "\t\n",
        "Condition_2: Proximity to various conditions (if more than one is present)\n",
        "\t\t\n",
        "       Artery\tAdjacent to arterial street\n",
        "       Feedr\tAdjacent to feeder street\t\n",
        "       Norm\tNormal\t\n",
        "       RRNn\tWithin 200' of North-South Railroad\n",
        "       RRAn\tAdjacent to North-South Railroad\n",
        "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
        "       PosA\tAdjacent to postive off-site feature\n",
        "       RRNe\tWithin 200' of East-West Railroad\n",
        "       RRAe\tAdjacent to East-West Railroad\n",
        "       \n",
        " Electrical: Electrical system\n",
        "\n",
        "       SBrkr\tStandard Circuit Breakers & Romex\n",
        "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
        "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
        "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
        "       Mix\tMixed\n",
        "       \n",
        " Exter_Cond: Evaluates the present condition of the material on the exterior\n",
        "\t\t\n",
        "       Ex\tExcellent\n",
        "       Gd\tGood\n",
        "       TA\tAverage/Typical\n",
        "       Fa\tFair\n",
        "       Po\tPoor\n",
        " \n",
        " Exter_Qual: Evaluates the quality of the material on the exterior \n",
        "\t\t\n",
        "       Ex\tExcellent\n",
        "       Gd\tGood\n",
        "       TA\tAverage/Typical\n",
        "       Fa\tFair\n",
        "       Po\tPoor\n",
        "\t\t\n",
        "Exterior_1st: Exterior covering on house\n",
        "\n",
        "       AsbShng\tAsbestos Shingles\n",
        "       AsphShn\tAsphalt Shingles\n",
        "       BrkComm\tBrick Common\n",
        "       BrkFace\tBrick Face\n",
        "       CBlock\tCinder Block\n",
        "       CemntBd\tCement Board\n",
        "       HdBoard\tHard Board\n",
        "       ImStucc\tImitation Stucco\n",
        "       MetalSd\tMetal Siding\n",
        "       Other\tOther\n",
        "       Plywood\tPlywood\n",
        "       PreCast\tPreCast\t\n",
        "       Stone\tStone\n",
        "       Stucco\tStucco\n",
        "       VinylSd\tVinyl Siding\n",
        "       Wd Sdng\tWood Siding\n",
        "       WdShing\tWood Shingles\n",
        "\t\n",
        "Exterior_2nd: Exterior covering on house (if more than one material)\n",
        "\n",
        "       AsbShng\tAsbestos Shingles\n",
        "       AsphShn\tAsphalt Shingles\n",
        "       BrkComm\tBrick Common\n",
        "       BrkFace\tBrick Face\n",
        "       CBlock\tCinder Block\n",
        "       CemntBd\tCement Board\n",
        "       HdBoard\tHard Board\n",
        "       ImStucc\tImitation Stucco\n",
        "       MetalSd\tMetal Siding\n",
        "       Other\tOther\n",
        "       Plywood\tPlywood\n",
        "       PreCast\tPreCast\n",
        "       Stone\tStone\n",
        "       Stucco\tStucco\n",
        "       VinylSd\tVinyl Siding\n",
        "       Wd Sdng\tWood Siding\n",
        "       WdShing\tWood Shingles\n",
        "       \n",
        "Foundation: Type of foundation\n",
        "\t\t\n",
        "       BrkTil\tBrick & Tile\n",
        "       CBlock\tCinder Block\n",
        "       PConc\tPoured Contrete\t\n",
        "       Slab\tSlab\n",
        "       Stone\tStone\n",
        "       Wood\tWood\n",
        "\t\t\n",
        "Full_Bath: Full bathrooms above grade\n",
        "\n",
        "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
        "\n",
        "       Typ\tTypical Functionality\n",
        "       Min1\tMinor Deductions 1\n",
        "       Min2\tMinor Deductions 2\n",
        "       Mod\tModerate Deductions\n",
        "       Maj1\tMajor Deductions 1\n",
        "       Maj2\tMajor Deductions 2\n",
        "       Sev\tSeverely Damaged\n",
        "       Sal\tSalvage only\n",
        "\t\t\n",
        "Gr_Liv_Area: Above grade (ground) living area square feet\n",
        "        \n",
        "Half_Bath: Half baths above grade\n",
        "\n",
        "Heating: Type of heating\n",
        "\t\t\n",
        "       Floor\tFloor Furnace\n",
        "       GasA\tGas forced warm air furnace\n",
        "       GasW\tGas hot water or steam heat\n",
        "       Grav\tGravity furnace\t\n",
        "       OthW\tHot water or steam heat other than gas\n",
        "       Wall\tWall furnace\n",
        "\t\t\n",
        "Heating_QC: Heating quality and condition\n",
        "\n",
        "       Ex\tExcellent\n",
        "       Gd\tGood\n",
        "       TA\tAverage/Typical\n",
        "       Fa\tFair\n",
        "       Po\tPoor\n",
        "\n",
        "House_Style: Style of dwelling\n",
        "\t\n",
        "       1Story\tOne story\n",
        "       1.5Fin\tOne and one-half story: 2nd level finished\n",
        "       1.5Unf\tOne and one-half story: 2nd level unfinished\n",
        "       2Story\tTwo story\n",
        "       2.5Fin\tTwo and one-half story: 2nd level finished\n",
        "       2.5Unf\tTwo and one-half story: 2nd level unfinished\n",
        "       SFoyer\tSplit Foyer\n",
        "       SLvl\tSplit Level\n",
        "\n",
        "Kitchen_AbvGr: Kitchens above grade\n",
        "\n",
        "Kitchen_Qual: Kitchen quality\n",
        "\n",
        "       Ex\tExcellent\n",
        "       Gd\tGood\n",
        "       TA\tTypical/Average\n",
        "       Fa\tFair\n",
        "       Po\tPoor\n",
        "\n",
        "LandContour: Flatness of the property\n",
        "\n",
        "       Lvl\tNear Flat/Level\t\n",
        "       Bnk\tBanked - Quick and significant rise from street grade to building\n",
        "       HLS\tHillside - Significant slope from side to side\n",
        "       Low\tDepression\n",
        "\t\t\n",
        "Land_Slope: Slope of property\n",
        "\t\t\n",
        "       Gtl\tGentle slope\n",
        "       Mod\tModerate Slope\t\n",
        "       Sev\tSevere Slope\n",
        "\n",
        "Lot_Area: Lot size in square feet\n",
        "\n",
        "Lot_Config: Lot configuration\n",
        "\n",
        "       Inside\tInside lot\n",
        "       Corner\tCorner lot\n",
        "       CulDSac\tCul-de-sac\n",
        "       FR2\tFrontage on 2 sides of property\n",
        "       FR3\tFrontage on 3 sides of property\n",
        "\n",
        "Lot_Shape: General shape of property\n",
        "\n",
        "       Reg\tRegular\t\n",
        "       IR1\tSlightly irregular\n",
        "       IR2\tModerately Irregular\n",
        "       IR3\tIrregular\n",
        "\n",
        "MS_SubClass: Identifies the type of dwelling involved in the sale.\t\n",
        "\n",
        "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
        "        30\t1-STORY 1945 & OLDER\n",
        "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
        "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
        "        50\t1-1/2 STORY FINISHED ALL AGES\n",
        "        60\t2-STORY 1946 & NEWER\n",
        "        70\t2-STORY 1945 & OLDER\n",
        "        75\t2-1/2 STORY ALL AGES\n",
        "        80\tSPLIT OR MULTI-LEVEL\n",
        "        85\tSPLIT FOYER\n",
        "        90\tDUPLEX - ALL STYLES AND AGES\n",
        "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
        "       150\t1-1/2 STORY PUD - ALL AGES\n",
        "       160\t2-STORY PUD - 1946 & NEWER\n",
        "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
        "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
        "\n",
        "MS_Zoning: Identifies the general zoning classification of the sale.\n",
        "\t\t\n",
        "       A\tAgriculture\n",
        "       C\tCommercial\n",
        "       FV\tFloating Village Residential\n",
        "       I\tIndustrial\n",
        "       RH\tResidential High Density\n",
        "       RL\tResidential Low Density\n",
        "       RP\tResidential Low Density Park \n",
        "       RM\tResidential Medium Density\n",
        "\n",
        "Mas_Vnr_Type: Masonry veneer type\n",
        "\n",
        "       BrkCmn\tBrick Common\n",
        "       BrkFace\tBrick Face\n",
        "       CBlock\tCinder Block\n",
        "       None\tNone\n",
        "       Stone\tStone\n",
        "\n",
        "Mo_Sold: Month Sold (MM)\n",
        "\n",
        "Neighborhood: Physical locations within Ames city limits\n",
        "\n",
        "       Blmngtn\tBloomington Heights\n",
        "       Blueste\tBluestem\n",
        "       BrDale\tBriardale\n",
        "       BrkSide\tBrookside\n",
        "       ClearCr\tClear Creek\n",
        "       CollgCr\tCollege Creek\n",
        "       Crawfor\tCrawford\n",
        "       Edwards\tEdwards\n",
        "       Gilbert\tGilbert\n",
        "       IDOTRR\tIowa DOT and Rail Road\n",
        "       MeadowV\tMeadow Village\n",
        "       Mitchel\tMitchell\n",
        "       Names\tNorth Ames\n",
        "       NoRidge\tNorthridge\n",
        "       NPkVill\tNorthpark Villa\n",
        "       NridgHt\tNorthridge Heights\n",
        "       NWAmes\tNorthwest Ames\n",
        "       OldTown\tOld Town\n",
        "       SWISU\tSouth & West of Iowa State University\n",
        "       Sawyer\tSawyer\n",
        "       SawyerW\tSawyer West\n",
        "       Somerst\tSomerset\n",
        "       StoneBr\tStone Brook\n",
        "       Timber\tTimberland\n",
        "       Veenker\tVeenker\n",
        "\t\t\t\n",
        "Overall_Cond: Rates the overall condition of the house\n",
        "\n",
        "       10\tVery Excellent\n",
        "       9\tExcellent\n",
        "       8\tVery Good\n",
        "       7\tGood\n",
        "       6\tAbove Average\t\n",
        "       5\tAverage\n",
        "       4\tBelow Average\t\n",
        "       3\tFair\n",
        "       2\tPoor\n",
        "       1\tVery Poor\n",
        "\n",
        "Overall_Qual: Rates the overall material and finish of the house\n",
        "\n",
        "       10\tVery Excellent\n",
        "       9\tExcellent\n",
        "       8\tVery Good\n",
        "       7\tGood\n",
        "       6\tAbove Average\n",
        "       5\tAverage\n",
        "       4\tBelow Average\n",
        "       3\tFair\n",
        "       2\tPoor\n",
        "       1\tVery Poor\n",
        "\n",
        "Paved_Drive: Paved driveway\n",
        "\n",
        "       Y\tPaved \n",
        "       P\tPartial Pavement\n",
        "       N\tDirt/Gravel\n",
        "\n",
        "Roof_Matl: Roof material\n",
        "\n",
        "       ClyTile\tClay or Tile\n",
        "       CompShg\tStandard (Composite) Shingle\n",
        "       Membran\tMembrane\n",
        "       Metal\tMetal\n",
        "       Roll\tRoll\n",
        "       Tar&Grv\tGravel & Tar\n",
        "       WdShake\tWood Shakes\n",
        "       WdShngl\tWood Shingles\n",
        "\n",
        "Roof_Style: Type of roof\n",
        "\n",
        "       Flat\tFlat\n",
        "       Gable\tGable\n",
        "       Gambrel\tGabrel (Barn)\n",
        "       Hip\tHip\n",
        "       Mansard\tMansard\n",
        "       Shed\tShed\n",
        "\n",
        "SalePrice: the sales price for each house\n",
        "\n",
        "Sale_Condition: Condition of sale\n",
        "\n",
        "       Normal\tNormal Sale\n",
        "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
        "       AdjLand\tAdjoining Land Purchase\n",
        "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
        "       Family\tSale between family members\n",
        "       Partial\tHome was not completed when last assessed (associated with New Homes)\n",
        "\n",
        "Sale_Type: Type of sale\n",
        "\t\t\n",
        "       WD \tWarranty Deed - Conventional\n",
        "       CWD\tWarranty Deed - Cash\n",
        "       VWD\tWarranty Deed - VA Loan\n",
        "       New\tHome just constructed and sold\n",
        "       COD\tCourt Officer Deed/Estate\n",
        "       Con\tContract 15% Down payment regular terms\n",
        "       ConLw\tContract Low Down payment and low interest\n",
        "       ConLI\tContract Low Interest\n",
        "       ConLD\tContract Low Down\n",
        "       Oth\tOther\n",
        "\t\n",
        "Street: Type of road access to property\n",
        "\n",
        "       Grvl\tGravel\t\n",
        "       Pave\tPaved\n",
        "       \t\n",
        "TotRms_AbvGrd: Total rooms above grade (does not include bathrooms)\n",
        "\n",
        "Utilities: Type of utilities available\n",
        "\t\t\n",
        "       AllPub\tAll public Utilities (E,G,W,& S)\t\n",
        "       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n",
        "       NoSeWa\tElectricity and Gas Only\n",
        "       ELO\tElectricity only\t\n",
        "\t\n",
        "Year_Built: Original construction date\n",
        "\n",
        "Year_Remod/Add: Remodel date (same as construction date if no remodeling or additions)\n",
        "\t\t\t\t\t\t\n",
        "Yr_Sold: Year Sold (YYYY)\t\n",
        "\n",
        "```"
      ]
    }
  ]
}