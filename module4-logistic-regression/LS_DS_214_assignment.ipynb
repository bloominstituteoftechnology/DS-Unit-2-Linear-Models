{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 1, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Project: Logistic Regression\n",
    "\n",
    "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
    "\n",
    "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
    "\n",
    "## Directions\n",
    "\n",
    "The tasks for this project are the following:\n",
    "\n",
    "- **Task 1:** Import `csv` file using `wrangle` function.\n",
    "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
    "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
    "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
    "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
    "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
    "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
    "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
    "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
    "\n",
    "**Note** \n",
    "\n",
    "You should limit yourself to the following libraries:\n",
    "\n",
    "- `category_encoders`\n",
    "- `matplotlib`\n",
    "- `pandas`\n",
    "- `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "    # Import w/ DateTimeIndex\n",
    "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
    "                     index_col='Date')\n",
    "    \n",
    "    # Drop unrated burritos\n",
    "    df.dropna(subset=['overall'], inplace=True)\n",
    "    \n",
    "    # Derive binary classification target:\n",
    "    # We define a 'Great' burrito as having an\n",
    "    # overall rating of 4 or higher, on a 5 point scale\n",
    "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
    "    \n",
    "    # Drop high cardinality categoricals\n",
    "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
    "    \n",
    "    # Drop columns to prevent \"leakage\"\n",
    "    df = df.drop(columns=['Rec', 'overall'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "filepath = DATA_PATH + 'burritos/burritos.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = DATA_PATH + 'burritos/burritos.csv'\n",
    "df = wrangle(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
    "\n",
    "```\n",
    "0      x\n",
    "1      x\n",
    "2    NaN\n",
    "3      x\n",
    "4      x\n",
    "Name: Beef, dtype: object\n",
    "```\n",
    "\n",
    "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct your exploratory data analysis here\n",
    "# And modify the `wrangle` function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
    "\n",
    "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
    "\n",
    "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
    "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
    "| California  |       1        |     0     |    0     |      0       |\n",
    "| California  |       1        |     0     |    0     |      0       |\n",
    "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
    "| Carne asada |       0        |     1     |    0     |      0       |\n",
    "| California  |       1        |     0     |    0     |      0       |\n",
    "\n",
    "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct your exploratory data analysis here\n",
    "# And modify the `wrangle` function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Split Data\n",
    "\n",
    "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
    "\n",
    "- Your training set should include data from 2016 through 2017. \n",
    "- Your test set should include data from 2018 and later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = ..., ...\n",
    "X_test, y_test = ..., ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Establish Baseline\n",
    "\n",
    "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_acc = ...\n",
    "print('Baseline Accuracy Score:', baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Build Model\n",
    "\n",
    "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
    "\n",
    "- a `OneHotEncoder` transformer for categorical features, \n",
    "- a `SimpleImputer` transformer to deal with missing values, \n",
    "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
    "- a `LogisticRegression` predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logr = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Check Metrics\n",
    "\n",
    "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = ...\n",
    "test_acc = ...\n",
    "\n",
    "print('Training MAE:', training_acc)\n",
    "print('Test MAE:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Communicate Results\n",
    "\n",
    "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
    "\n",
    "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your horizontal barchart here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
    "\n",
    "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
    "\n",
    "- What data type do `predict` and `predict_proba` output?\n",
    "- What are the shapes of their different output?\n",
    "- What numerical values are in the output?\n",
    "- What do those numerical values represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here to explore the differences between `predict` and `predict_proba`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give your written answer here:**\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_214_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
