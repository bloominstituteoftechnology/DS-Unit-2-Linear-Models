{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of assignment_regression_classification_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgXcgn0nKPeN",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- âœ”ï¸ Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- âœ”ï¸ Begin with baselines for classification.\n",
        "- âœ”ï¸ Use scikit-learn for logistic regression.\n",
        "- âœ”ï¸ Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- âœ”ï¸ Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "- [ ] Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awn6uOJkKPeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2fxPZjBKPeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csi_0IBNKPea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJO6G0lTKPed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7PRAriXKPef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQsNjaPOTbtk",
        "colab_type": "text"
      },
      "source": [
        "### Do train/validate/test split.\n",
        "\n",
        "Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hk5z9hlUqHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all nans\n",
        "df = df.drop(columns='Queso')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUxppBZtKPei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "df_train = df[df['Date'].dt.year < 2017]\n",
        "df_val = df[df['Date'].dt.year == 2017]\n",
        "df_test = df[df['Date'].dt.year > 2017]\n",
        "df_train = df_train.drop(columns='Date')\n",
        "df_val = df_val.drop(columns='Date')\n",
        "df_test = df_test.drop(columns='Date')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4JtcLUOU60O",
        "colab_type": "text"
      },
      "source": [
        "### Begin with baselines for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb8MpCJMU8qC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f8066507-e030-4b78-84f1-69272537cc54"
      },
      "source": [
        "y_col = 'Great'\n",
        "X_cols = df_train.drop(columns='Great').columns # lol\n",
        "\n",
        "# Simple majority baseline\n",
        "from sklearn.dummy import DummyClassifier\n",
        "model = DummyClassifier(strategy='most_frequent')\n",
        "model.fit(df_train[X_cols], df_train[y_col])\n",
        "\n",
        "# how'd we do?\n",
        "valscore = model.score(df_val[X_cols], df_val[y_col])\n",
        "testscore = model.score(df_test[X_cols], df_test[y_col])\n",
        "print('Simple Majority Baseline')\n",
        "print(f'Validation Score: {valscore:.2f}')\n",
        "print(f'Test Score: {testscore:.2f}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Majority Baseline\n",
            "Validation Score: 0.55\n",
            "Test Score: 0.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzZd8Cdekbk2",
        "colab_type": "text"
      },
      "source": [
        "### Use scikit-learn for logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h90l59hkl5Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# only use numeric columns\n",
        "X_cols = ['Cost', 'Hunger', 'Mass (g)', 'Density (g/mL)', 'Length', 'Circum',\n",
        "          'Volume', 'Tortilla', 'Temp', 'Meat', 'Fillings', 'Meat:filling',\n",
        "          'Uniformity', 'Salsa', 'Synergy', 'Wrap']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNmxXYyilP59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train[X_cols]\n",
        "X_val = df_val[X_cols]\n",
        "X_test = df_test[X_cols]\n",
        "y_train = df_train[y_col]\n",
        "y_val = df_val[y_col]\n",
        "y_test = df_test[y_col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB29Xi06mQ16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# impute nans\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train = imputer.fit_transform(X_train, y_train)\n",
        "X_val = imputer.transform(X_val)\n",
        "X_test = imputer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxzLS_gKkdYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "42e4d79c-273d-4fe6-e671-2c4509d73805"
      },
      "source": [
        "# use k-fold cross validation\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "model = LogisticRegressionCV(cv=5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# how'd we do?\n",
        "valscore = model.score(X_val, y_val)\n",
        "testscore = model.score(X_test, y_test)\n",
        "print('Logistic Regression w/ CV')\n",
        "print(f'Validation Score: {valscore:.2f}')\n",
        "print(f'Test Score: {testscore:.2f}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression w/ CV\n",
            "Validation Score: 0.88\n",
            "Test Score: 0.79\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
