{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "S@ mar21-1AM REGRSS2-unit2 spr1 mod2- 212 assmnt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LambdaTheda/DS-Unit-2-Linear-Models/blob/master/S_mar21_1AM_REGRSS2_unit2_spr1_mod2_212_assmnt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKud5_tfUSQT",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Regression 2\n",
        "\n",
        "## Assignment\n",
        "\n",
        "You'll continue to **predict how much it costs to rent an apartment in NYC,** using the dataset from renthop.com.\n",
        "\n",
        "- [ ] Do train/test split. Use data from April & May 2016 to train. Use data from June 2016 to test.\n",
        "- [ ] Engineer at least two new features. (See below for explanation & ideas.)\n",
        "- [ ] Fit a linear regression model with at least two features.\n",
        "- [ ] Get the model's coefficients and intercept.\n",
        "- [ ] Get regression metrics RMSE, MAE, and $R^2$, for both the train and test data.\n",
        "- [ ] What's the best test MAE you can get? Share your score and features used with your cohort on Slack!\n",
        "- [ ] As always, commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "#### [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering)\n",
        "\n",
        "> \"Some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.\" — Pedro Domingos, [\"A Few Useful Things to Know about Machine Learning\"](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
        "\n",
        "> \"Coming up with features is difficult, time-consuming, requires expert knowledge. 'Applied machine learning' is basically feature engineering.\" — Andrew Ng, [Machine Learning and AI via Brain simulations](https://forum.stanford.edu/events/2011/2011slides/plenary/2011plenaryNg.pdf) \n",
        "\n",
        "> Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. \n",
        "\n",
        "#### Feature Ideas\n",
        "- Does the apartment have a description?\n",
        "- How long is the description?\n",
        "- How many total perks does each apartment have?\n",
        "- Are cats _or_ dogs allowed?\n",
        "- Are cats _and_ dogs allowed?\n",
        "- Total number of rooms (beds + baths)\n",
        "- Ratio of beds to baths\n",
        "- What's the neighborhood, based on address or latitude & longitude?\n",
        "\n",
        "## Stretch Goals\n",
        "- [ ] If you want more math, skim [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf),  Chapter 3.1, Simple Linear Regression, & Chapter 3.2, Multiple Linear Regression\n",
        "- [ ] If you want more introduction, watch [Brandon Foltz, Statistics 101: Simple Linear Regression](https://www.youtube.com/watch?v=ZkjP5RJLQF4)\n",
        "(20 minutes, over 1 million views)\n",
        "- [ ] Add your own stretch goal(s) !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'\n",
        "    \n",
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cvrw-T3bZOuW",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Read New York City apartment rental listing data\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "df = pd.read_csv(DATA_PATH+'apartments/renthop-nyc.csv')\n",
        "assert df.shape == (49352, 34)\n",
        "\n",
        "# Remove the most extreme 1% prices,\n",
        "# the most extreme .1% latitudes, &\n",
        "# the most extreme .1% longitudes\n",
        "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
        "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
        "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
        "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
        "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
        "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCmFCOqHo4mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLuF3n1XBBx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UPNE8MTpzeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj8HrtK82qpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train/test split. Use data from April & May 2016 to train. \n",
        "\n",
        "df['created'] = pd.to_datetime(df['created'])\n",
        "train = df[(df['created'].dt.year == 2016) & (df['created'].dt.month.isin([4, 5]))]\n",
        "train.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_LriD5a--KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# explore column to use for train/test split\n",
        "df['created'].value_counts(48817) # returns counts as < 1 (bc of dt classes? or https://www.w3resource.com/pandas/series/series-value_counts.php- SERIES notdf fcngit)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACVZjBIPXl-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['created'].value_counts(48817).head(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR9B3knVV3SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# explore column to use for train/test split\n",
        "df['created'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiV7lQ9WWl4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['created'].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEeh_JKcX82Y",
        "colab_type": "text"
      },
      "source": [
        "#  train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtuNNTyxvWeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ATTEMPT 3: Parsing out only YEAR from df['created']-\n",
        "df['created'] = pd.to_datetime(df['created']) #dot notation: df['created'] = pd.to_datetime(df.created); from https://www.youtube.com/watch?v=yCgJGsg0Xa4\n",
        "df['year'] = df['created'].dt.year\n",
        "df['year']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoxtNV8769cB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#temp df for making train set from df with df['created'].dt.year == 2016\n",
        "df_train_yr = df[(df['year'] == 2016)]\n",
        "df_train_yr.head(200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBdIYuvIYQMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_yr.nunique"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K2-2i5-bn-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_train_yr.value_counts() #AttributeError: 'DataFrame' object has no attribute 'value_counts'; BC NO CLASSES ?#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVahknVGCdNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filter df_train_yr for April and May rows- WORKS\n",
        "df_train_yr_and_months = df_train_yr[df_train_yr['created'].dt.month.isin([4, 5])]  #df[(df['year'] == 2016)]\n",
        "df_train_yr_and_months.head(200)          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUabj3stD7hL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_yr_and_months.sample(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F81irlJ-EIq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train_yr_and_months\n",
        "df_train.head(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PpQC3RBG99p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvoJ7PgYfg7M",
        "colab_type": "text"
      },
      "source": [
        "# FILTER df_train TO MAKE TEST SET USING JUNE 2016 ROWS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoSxJRaMQh2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['created'] = pd.to_datetime(df['created'])\n",
        "df['created'].dtype"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EHq_hurL-u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATTEMPT 2: AttributeError: 'str' object has no attribute 'dt'\n",
        "'''\n",
        "df['created'] = pd.to_datetime(df['created'])\n",
        "\n",
        "df['month'] = df['created'].dt.month\n",
        "\n",
        "df_test = df_train_yr[df_train_yr['created'.dt.month] == 6] \n",
        "df_test\n",
        "'''\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y4ix_ceR1xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATTEMPT 3: WORKS\n",
        "\n",
        "df['created'] = pd.to_datetime(df['created'])\n",
        "#df['created'].dtype            # RETURNS dtype('<M8[ns]')\n",
        "df_test = df_train_yr[df_train_yr['created'].dt.month.isin([6])]\n",
        "df_test.head(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86GrBSCYUtqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx-udb7uVXZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['created'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i65dLUOXRkvW",
        "colab_type": "text"
      },
      "source": [
        "# \"my own\" S t     r            e           T                c  h                                          GOAL!  3d plot of 3 features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3X7_hlNRvb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "px.scatter_3d(\n",
        "    df,\n",
        "    x = 'bedrooms',\n",
        "    y = 'price',\n",
        "    z = 'bathrooms', \n",
        "    title = 'NYC Apartment Rental Prices, 2016'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xz9wu-ugjtd",
        "colab_type": "text"
      },
      "source": [
        "# Engineer at least two new features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAjZvTgEjGs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) Does the apartment have a description? ATTEMPTS/Exploration\n",
        "\n",
        "# Using for loop\n",
        "# for descrp in range (len(df['description'])):  \n",
        "\n",
        "# Chris suggests apply():\n",
        "\n",
        " # use regex to find '     ' string that seems to represent no descriptions\n",
        "'''\n",
        "import re \n",
        "no = re.compile('        ')\n",
        "no    # RETURNS: re.compile(r'        ', re.UNICODE)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoMo70MVEi-B",
        "colab_type": "text"
      },
      "source": [
        "# 1) FEATURE ENGINEERED 'has_description' column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YPONoMO2C2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) FEATURE ENGINEERED 'has_description' column: Does the apartment have a description?\n",
        "# set the new column to the dataframe column with all values EXCEPT '        '\n",
        "df['has_description'] = ~df['description'].isin(['        '])\n",
        "\n",
        "df['has_description'] = df['has_description'].map({True: 'Yes', False: 'No'})\n",
        "\n",
        "df['has_description']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-HGHdxC8SVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.sample(200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcqJW8KcVYMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use findall() \n",
        "'''\n",
        "no.findall('        ')\n",
        "print(df['description'].no.findall('        ')) # RETURNS: AttributeError: 'Series' object has no attribute 'no'\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnhqq6SsEfoY",
        "colab_type": "text"
      },
      "source": [
        "# 2) FEATURE ENGINEERED 'total_rooms' column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xQu-UpjkKJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) FEATURE ENGINEERED 'total_rooms' column: Total number of rooms (beds + baths)\n",
        "df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcdfpaR9E7mZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4eb729bb-852e-4abe-9610-325848d44c2b"
      },
      "source": [
        "#Check the columns\n",
        "df.columns"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bathrooms', 'bedrooms', 'created', 'description', 'display_address',\n",
              "       'latitude', 'longitude', 'price', 'street_address', 'interest_level',\n",
              "       'elevator', 'cats_allowed', 'hardwood_floors', 'dogs_allowed',\n",
              "       'doorman', 'dishwasher', 'no_fee', 'laundry_in_building',\n",
              "       'fitness_center', 'pre-war', 'laundry_in_unit', 'roof_deck',\n",
              "       'outdoor_space', 'dining_room', 'high_speed_internet', 'balcony',\n",
              "       'swimming_pool', 'new_construction', 'terrace', 'exclusive', 'loft',\n",
              "       'garden_patio', 'wheelchair_access', 'common_outdoor_space', 'year',\n",
              "       'has_description', 'total_rooms', 'year_created', 'month_created'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FllM2V8nQ2Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop target and categorical columns WHY NOT WORKING!@?#\n",
        "'''\n",
        "df.drop(columns=['price','description',\n",
        "        'display_address',\n",
        "        'street_address',\n",
        "        'interest_level']], axis=1)\n",
        "\n",
        "df.columns\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDkDaqcJEr-N",
        "colab_type": "text"
      },
      "source": [
        "# Fit a linear regression model with at least two features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrcDBUEpq0Tf",
        "colab_type": "text"
      },
      "source": [
        "## 5 Step Process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j2ZeEiXEx3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5 Step Process:\n",
        "# 1) Import appropriate estimator class from sklearn\n",
        "\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv2-WMogFWnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) Instantiate this class\n",
        "model = LinearRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ExGBxj9qe3m",
        "colab_type": "text"
      },
      "source": [
        "# 3 WAYS TO SPLIT TRAIN/TEST DATASETS/dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct6M2rIuV3w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3a) Arrange X FEATURES matrices- ONE WAY:\n",
        "\n",
        "df['created'] = pd.to_datetime(df['created'], infer_datetime_format=True) # change dtype from string to datetime to access month, day, yr etc\n",
        "\n",
        "# filter out year 2016\n",
        "df['year_created'] = df['created'].dt.year    # access yr\n",
        "df = df[df['year_created'] == 2016]\n",
        "\n",
        "df['month_created'] = df['created'].dt.month  # access month\n",
        "\n",
        "# filter out months Apr & May for TRAIN set\n",
        "train = df[(df['month_created'] == 4) | (df['month_created'] == 5)]\n",
        "\n",
        "# filter out month June for TEST set\n",
        "test = df[df['month_created'] == 6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uR6bfOcWpnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJRCX_WXBbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3b) Arrange X FEATURES MATRICES- a 2nd WAY\n",
        "\n",
        "features = ['total_rooms', 'has_description'] # a python list, called features, containing these 2 columns' data\n",
        "\n",
        "X_train = train[features] # split 2 chosen features' columns' row fields into train dataframe matrix\n",
        "X_test  =  test[features] # split \" \" \" \" \" \" into test dataframe matrix\n",
        "\n",
        "X_train, X_test #BEST WAY TO VISUALIZE? shape below? head()?\n",
        "\n",
        "# Arrange y target Matrix\n",
        "target = 'price'  # target is an sklearn df? attribute that allows one to access the target values (fields?) aka labels- CHRIS TL said NOT IN GENERAL\n",
        "                  # else Colab/python (which) recognizes it as one of the columns (color change), and can ALWAYS? set a col to a var w/o calling?/using the df[]?\n",
        "\n",
        "#Drop target column from features to prevent data leakage and over-fitting\n",
        "'''\n",
        "features = df.columns.drop('price',\n",
        "        'description',\n",
        "        'display_address',\n",
        "        'street_address',\n",
        "        'interest_level')\n",
        "''' # TypeError: drop() takes from 2 to 3 positional arguments but 6 were given\n",
        "\n",
        "\n",
        "y_train = train[target]  # predicted y target column (no x, only y) values output for passed in features datapoints in/from TRAIN DATASET/dataframe\n",
        "y_test  =  test[target]  # predicted y target column (no x, only y) values output for passed in features datapoints in/from TEST DATASET/dataframe\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE5C3k1vohPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Linear Regression, dependent upon: {features}')\n",
        "print('X_train.shape: ', X_train.shape, '\\n' ' X_test.shape: ', X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP4EuGxTguws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# 3b) a 3rd way to split test/train using the TRAIN_TEST_SPLIT METHOD\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKGufxWTGZ4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df['has_description'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwERjPqMGujM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a25d691-672b-4ce5-c7b7-7f07d85f08bc"
      },
      "source": [
        "df['has_description'].dtype"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAwnUY_IJbZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81kanra_JnG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' DROP obj datatype cols for model\n",
        "df.drop('description',\n",
        "        'display_address',\n",
        "        'street_address',\n",
        "        'interest_level',\n",
        "       )\n",
        "\n",
        "df.columns()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKMLJx0_vMq0",
        "colab_type": "code",
        "outputId": "8d4758b2-7c9b-4659-db95-fc4dd2ad8dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "source": [
        "#4) CONVERT categorical columns to numerical for model: One-hot encoding of 'has_description'\n",
        "import category_encoders as ce\n",
        "\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "\n",
        "#y_train_encoded = encoder.fit_transform(y_train)  #KeyError: 'has_description'\n",
        "\n",
        "print(X_train_encoded.shape, X_test_encoded.shape)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'has_description'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-9657cff98e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/category_encoders/one_hot.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mhandle_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         )\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordinal_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordinal_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/category_encoders/ordinal.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mhandle_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         )\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/category_encoders/ordinal.py\u001b[0m in \u001b[0;36mordinal_encoding\u001b[0;34m(X_in, mapping, cols, handle_unknown, handle_missing)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mnan_identity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_category\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                     \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'has_description'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkiMRd3nFANu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#One-hot encoding: specify 'has_description' column to encode and replace original with encoded version\n",
        "df['has_description'] = encoder.fit_transform(df['has_description']) #AttributeError: module 'category_encoders' has no attribute 'fit_transform'\n",
        "df['has_description']  # One hot encoding TRANSFORMED \"Yes\" into 1 and \"No\" into 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqLvlIo1JCCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit still gives ValueError: could not convert string to float: 'Yes'- change to 1 = Yes, 0 = No, or One Hot Encode\n",
        "#trying type casting int64 to float with .astype()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ykSWkUq7sd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5674f281-99db-430e-a20e-379e9fb432c4"
      },
      "source": [
        "#4a) fit model on TRAIN DATASET\n",
        "model.fit(X_train_encoded, y_train) # ValueError: could not convert string to float: 'Yes'- change to 1 = Yes, 0 = No, or One Hot Encode"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ViqRR471xhH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "e27baa3d-cf49-4bea-c7c7-d332b276de65"
      },
      "source": [
        "# 5a) calculate Train error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "y_pred = model.predict(X_train) # get prediction of y target values \n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "print(f'Train Error: {mae:.2f} percentage points')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-90dae1ee8277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get prediction of y target values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train Error: {mae:.2f} percentage points'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \"\"\"\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    209\u001b[0m                                dense_output=True) + self.intercept_\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Yes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWQxQ3Vf2Quj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5b) calculate Test error\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Test Error: {mae:.2f} percentage points')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnm9MKCm14-p",
        "colab_type": "text"
      },
      "source": [
        "# Get the model's coefficients and intercept."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3ydeDKl16tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model.coef_, model.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKstCU-02B1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# equation for the model\n",
        "beta0 = model.intercept_\n",
        "beta1, beta2 = model.coef_\n",
        "print(f'y = {beta0} + {beta1}x1 + {beta2}x2')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by7hArNu2Z2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model's coefficients and intercept. \n",
        "print('Intercept', model.intercept_)\n",
        "coefficients = pd.Series(model.coef_, features)\n",
        "print(coefficients.to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrwzqKD1aK2",
        "colab_type": "text"
      },
      "source": [
        "## Get regression metrics RMSE, MAE, and  𝑅2 , for both the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "porQxtpN1kqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regression metrics for TRAIN data\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "\n",
        "mse = mean_squared_error(y_train, y_pred)  #Mean squared error\n",
        "\n",
        "rmse = np.sqrt(mse)                        #root mean squared Error\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred) #mean absolute Error\n",
        "\n",
        "r2 = r2_score(y_train, y_pred)             #r^2\n",
        "\n",
        "print('Mean Squared Error:', mse)\n",
        "print('Root Mean Squared Error:', rmse)\n",
        "print('Mean Absolute Error:', mae)\n",
        "print('R^2:', r2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfCGWAhS1qhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regression metrics for TEST data\n",
        "y_pred = model.predict(X_test) \n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)  #Mean squared error\n",
        "\n",
        "rmse = np.sqrt(mse)                       #root mean squared Error\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred) #mean absolute Error\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)             #r^2\n",
        "\n",
        "print('Mean Squared Error:', mse)\n",
        "print('Root Mean Squared Error:', rmse)\n",
        "print('Mean Absolute Error:', mae)\n",
        "print('R^2:', r2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}